{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fafc5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle \n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from operator import itemgetter\n",
    "\n",
    "from utils.tree_utils import *\n",
    "from utils.utils import *\n",
    "from dataset import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89fd0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75e3fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../data/'\n",
    "data_dir = '../data/'\n",
    "journalist = 'carolecadwalla'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e43c9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [00:00<00:00, 1752.72it/s]\n",
      "100%|██████████| 689/689 [00:00<00:00, 1260.35it/s]\n"
     ]
    }
   ],
   "source": [
    "dp = []\n",
    "rel = []\n",
    "journal_sort = pd.read_csv((os.path.join(data_dir, f'{journalist}/{journalist}_conv_labels.csv')))\n",
    "ids = []\n",
    "for item in list(journal_sort['conversation_id']):\n",
    "    if item not in ids:\n",
    "        ids.append(item)\n",
    "id_pair = {}\n",
    "id_conv = {}\n",
    "for idx in ids:\n",
    "    id_pair[idx], id_conv[idx] = create_conversation_list(journal_sort[journal_sort['conversation_id']==idx], idx)\n",
    "id_data, uid, data, label = create_data(journal_sort, ids)\n",
    "prob = pkl.load(open(os.path.join(data_dir, f'{journalist}/{journalist}_edgeprob.pkl'), 'rb'))\n",
    "\n",
    "with open(os.path.join(data_dir, f'{journalist}/{journalist}_global_path.txt'), \"r\") as f:\n",
    "    for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "        dp.append(json.loads(line.strip()))\n",
    "\n",
    "with open(os.path.join(data_dir, f'{journalist}/{journalist}_local_path.txt'), \"r\") as f:\n",
    "    for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "        rel.append(json.loads(line.strip()))\n",
    "global_input = convert_global(dp, id_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f2a5ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9422a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(set_list, n):\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Split sizes\n",
    "    train_size = int(0.7 * n)\n",
    "    validation_size = int(0.3 * n)\n",
    "    test_size = n\n",
    "    # Split indices\n",
    "    train_indices = list(indices[:train_size])\n",
    "    dev_indices = list(indices[train_size:train_size+validation_size])\n",
    "    test_indices = list(indices[train_size+validation_size:])\n",
    "\n",
    "    get_items_tr = itemgetter(*train_indices)  # Creates a callable for indexing\n",
    "    get_items_dev = itemgetter(*dev_indices)\n",
    "    get_items_te = itemgetter(*test_indices)\n",
    "    result_tr = list(get_items_tr(set_list))\n",
    "    result_dev = list(get_items_dev(set_list))\n",
    "    result_te = list(get_items_te(set_list))\n",
    "\n",
    "    result_train = result_tr if isinstance(result_tr, list) else [result_tr]\n",
    "    result_val = result_dev if isinstance(result_dev, list) else [result_dev]\n",
    "    result_test = result_te if isinstance(result_te, list) else [result_te]\n",
    "\n",
    "    return result_train, result_val, result_test\n",
    "\n",
    "def load_data(data_dir, journalist, classes, batch_size, collate):\n",
    "    ### Data (normalize input inter-event times, then padding to create dataloaders)\n",
    "    num_classes, num_sequences = 0, 0\n",
    "    seq_dataset = []\n",
    "    arr = []\n",
    "    dp = []\n",
    "    rel = []\n",
    "    \n",
    "    split = [4, 16]\n",
    "    # JiayangFan: 8: 84\n",
    "    # muyixiao: 4: 16\n",
    "    # lingling: 8, 99\n",
    "    # marianna: 2: 10\n",
    "    val = 0\n",
    "    journal_sort = pd.read_csv((os.path.join(data_dir, f'{journalist}/{journalist}_conv_labels.csv')))\n",
    "    ids = []\n",
    "    for item in list(journal_sort['conversation_id']):\n",
    "        if item not in ids:\n",
    "            ids.append(item)\n",
    "    id_pair = {}\n",
    "    id_conv = {}\n",
    "    for idx in ids:\n",
    "        id_pair[idx], id_conv[idx] = create_conversation_list(journal_sort[journal_sort['conversation_id']==idx], idx)\n",
    "    id_data, uid, data, label = create_data(journal_sort, ids)\n",
    "    prob = pkl.load(open(os.path.join(data_dir, f'{journalist}/{journalist}_edgeprob.pkl'), 'rb'))\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'{journalist}/{journalist}_global_path.txt'), \"r\") as f:\n",
    "        for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "            dp.append(json.loads(line.strip()))\n",
    "\n",
    "    with open(os.path.join(data_dir, f'{journalist}/{journalist}_local_path.txt'), \"r\") as f:\n",
    "        for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "            rel.append(json.loads(line.strip()))\n",
    "    \n",
    "    global_input = convert_global(dp, id_data)\n",
    "    local_data = convert_local(rel)\n",
    "    local_mat = generate_local_mat(local_data, id_data)\n",
    "    local_input = create_mat(local_mat, mat_type='concat')\n",
    "    logging.info(f'loaded split {journalist}...')\n",
    "    # data - dict: dim_process, devtest, args, train, dev, test, index (train/dev/test given as)\n",
    "    # data[split] - list dicts {'time_since_start': at, 'time_since_last_event': dt, 'type_event': mark} or\n",
    "    # data[split] - dict {'arrival_times', 'delta_times', 'marks'}\n",
    "    # data['dim_process'] = Number of accounts = 119,298\n",
    "    # num_sequences: number of conversations of a journalist\n",
    "    num_classes = classes\n",
    "    #num_sequences += len(data[split]['arrival_times'])\n",
    "    num_sequences = len(set(journal_sort['conversation_id']))\n",
    "    \n",
    "    # id_train, id_dev, id_test = id_data[:split[0]], id_data[split[0]:split[1]], id_data[split[1]:]\n",
    "    # uid_train, uid_dev, uid_test = uid[:split[0]], uid[split[0]:split[1]], uid[split[1]:]\n",
    "    # X_train, X_dev, X_test = data[:split[0]], data[split[0]:split[1]], data[split[1]:]\n",
    "    # prob_train, prob_dev, prob_test = prob[:split[0]], prob[split[0]:split[1]], prob[split[1]:]\n",
    "    # global_train, global_dev, global_test = global_input[:split[0]], global_input[split[0]:split[1]], global_input[split[1]:]\n",
    "    # local_train, local_dev, local_test = local_input[:split[0]], local_input[split[0]:split[1]], local_input[split[1]:]\n",
    "    # label_train, label_dev, label_test = label[:split[0]], label[split[0]:split[1]], label[split[1]:]\n",
    "\n",
    "    id_train, id_dev, id_test = id_data[split[0]:split[1]], id_data[:split[0]], id_data[split[1]:]\n",
    "    uid_train, uid_dev, uid_test = uid[split[0]:split[1]], uid[:split[0]], uid[split[1]:]\n",
    "    X_train, X_dev, X_test = data[split[0]:split[1]], data[:split[0]], data[split[1]:]\n",
    "    prob_train, prob_dev, prob_test = prob[split[0]:split[1]], prob[:split[0]], prob[split[1]:]\n",
    "    global_train, global_dev, global_test = global_input[split[0]:split[1]], global_input[:split[0]], global_input[split[1]:]\n",
    "    local_train, local_dev, local_test = local_input[split[0]:split[1]], local_input[:split[0]], local_input[split[1]:]\n",
    "    label_train, label_dev, label_test = label[split[0]:split[1]], label[:split[0]], label[split[1]:]\n",
    "\n",
    "    # n = 16\n",
    "    # id_train, id_dev, id_test = get_set(id_data, n)\n",
    "    # uid_train, uid_dev, uid_test = get_set(uid, n)\n",
    "    # X_train, X_dev, X_test = get_set(data, n)\n",
    "    # prob_train, prob_dev, prob_test = get_set(prob, n)\n",
    "    # global_train, global_dev, global_test = get_set(global_input, n)\n",
    "    # local_train, local_dev, local_test = get_set(local_input, n)\n",
    "    # label_train, label_dev, label_test = get_set(label, n)\n",
    "    \n",
    "    d_train = TreeDataset(id_train, uid_train, X_train, prob_train, global_train, local_train, label_train)\n",
    "    d_val = TreeDataset(id_dev, uid_dev, X_dev, prob_dev, global_dev, local_dev, label_dev)  \n",
    "    d_test  = TreeDataset(id_test, uid_test, X_test, prob_test, global_test, local_test, label_test)   \n",
    "\n",
    "    # for padding input sequences to maxlen of batch for running on gpu, and arranging them by length efficient\n",
    "    collate = collate  \n",
    "    dl_train = torch.utils.data.DataLoader(d_train, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "    dl_val = torch.utils.data.DataLoader(d_val, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "    dl_test = torch.utils.data.DataLoader(d_test, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "    return dl_train, dl_val, dl_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fba7ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2278.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1890.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# data, labels, prob, global_path, local_path, torch.tensor(masks)\n",
    "train, val, test = load_data(out_dir, journalist, 3, 4, collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95c7d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "feature_dim = 11  # Dimension of each feature in the input\n",
    "global_dim = 3\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "num_layers = 3\n",
    "dropout = 0.1\n",
    "forward_expansion = 4\n",
    "max_len = 500  # Adjust as per your sequence length\n",
    "num_classes = 3  # Number of classes\n",
    "mode = 'all'\n",
    "\n",
    "# Instantiate model\n",
    "model = CustomTransformerModel(feature_dim, global_dim, embed_size, num_classes, \n",
    "                               num_heads, num_layers, dropout, forward_expansion, max_len, mode)\n",
    "\n",
    "strat_model = StratModel(embed_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer_strat = optim.Adam(strat_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b979adb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'c_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m output, p_output, output_to_strat \u001b[38;5;241m=\u001b[39m model(data, dp, rel, mask)\n\u001b[1;32m     24\u001b[0m prob_tr\u001b[38;5;241m.\u001b[39mappend(p_output)\n\u001b[0;32m---> 25\u001b[0m prob_output \u001b[38;5;241m=\u001b[39m \u001b[43mstrat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     27\u001b[0m pred_tr\u001b[38;5;241m.\u001b[39mextend(predicted\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'c_input'"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "min_loss = float('inf')\n",
    "\n",
    "best_model_path = os.path.join(out_dir, f'{journalist}/best_model_w_strat.pth')\n",
    "best_strat_model_path = os.path.join(out_dir, f'{journalist}/best_strat_model_w_strat.pth')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "strat = True\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    pred_tr = []\n",
    "    true_tr = []\n",
    "    prob_tr = []\n",
    "    output_tr = []\n",
    "    for item in train:\n",
    "        data = item.data.float()\n",
    "        dp = item.global_path.float()\n",
    "        rel = item.local_path.float()\n",
    "        prob = item.prob.float()\n",
    "        targets = item.labels.long()\n",
    "        mask = item.masks.float()\n",
    "        mask_bool = mask.bool()\n",
    "        \n",
    "        output, p_output, c_output = model(data, dp, rel, mask)\n",
    "        #output, p_output = model(data, dp, rel, mask)\n",
    "        prob_tr.append(p_output)\n",
    "        prob_output = strat_model(p_output.detach(), c_output.detach())\n",
    "        #print(data.size, prob_output.size(), prob.size())\n",
    "        _, predicted = torch.max(output.data, 2)\n",
    "        output_tr.append(p_output.tolist())\n",
    "        pred_tr.extend(predicted.view(-1).tolist())\n",
    "        true_tr.extend(targets.view(-1).tolist())\n",
    "        correct_tr = sum(p == t for p, t in zip(pred_tr, true_tr))\n",
    "        acc_tr = correct_tr / len(true_tr)\n",
    "            \n",
    "        loss = criterion(output.view(-1, num_classes), targets.view(-1))\n",
    "        \n",
    "        # Apply the padding mask\n",
    "        loss = loss * mask\n",
    "        \n",
    "        # Compute the mean loss, considering only non-padded elements\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if strat == True:\n",
    "            # Dot product between probability_output and prob\n",
    "            dot_product = torch.sum(prob_output * prob, dim=-1)  # Sum over the last dimension\n",
    "            # Taking negative logarithm; adding a small value for numerical stability\n",
    "            log_loss = -torch.log(dot_product + 1e-9)  \n",
    "            # Masking and averaging the additional loss\n",
    "            loss_strat = (log_loss * mask).sum() / mask.sum()\n",
    "            # Combine the losses\n",
    "            total_loss = loss + loss_strat\n",
    "            optimizer_strat.zero_grad()\n",
    "            loss_strat.backward()  # No need to retain graph here\n",
    "            optimizer_strat.step()\n",
    "            #total_loss.backward()\n",
    "            #optimizer.step()\n",
    "\n",
    "        else:\n",
    "            total_loss = loss\n",
    "            #total_loss.backward()\n",
    "            #optimizer.step()\n",
    "        \n",
    "    if loss.item() < min_loss:\n",
    "        min_loss = loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/10], New Min Loss: {min_loss}, New Strategy Loss: {total_loss}, Acc: {acc_tr}\")\n",
    "        # Save the model state\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        torch.save(strat_model.state_dict(), best_strat_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load the best model for testing\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "strat_model.load_state_dict(torch.load(best_strat_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80be3f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjournalist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best_model_w_strat.pth\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      2\u001b[0m best_strat_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjournalist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best_strat_model_w_strat.pth\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m strat_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, best_strat_model_path)))\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1032\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:1437\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1435\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1436\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1437\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1440\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1442\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:1407\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1406\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1407\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:1381\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1381\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1382\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1383\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1386\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:390\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 390\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:265\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 265\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    267\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/torch/serialization.py:249\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    246\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    253\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    254\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "best_model_path = os.path.join(f'{journalist}/best_model_w_strat.pth') \n",
    "best_strat_model_path = os.path.join(f'{journalist}/best_strat_model_w_strat.pth') \n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(out_dir, best_model_path)))\n",
    "strat_model.load_state_dict(torch.load(os.path.join(out_dir, best_strat_model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e3cc228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     true_labels\u001b[38;5;241m.\u001b[39mextend(targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     28\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p \u001b[38;5;241m==\u001b[39m t \u001b[38;5;28;01mfor\u001b[39;00m p, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(predictions, true_labels))\n\u001b[0;32m---> 29\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_predictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Test Phase (after all epochs are done)\n",
    "model.eval()\n",
    "strat_model.eval()\n",
    "#best_model_path = 'best_model_w_strat.pth'\n",
    "#best_strat_model_path = 'best_strat_model_w_strat.pth'\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    test_steps = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    strat_li = []\n",
    "    for item in tqdm(val):  # Assuming 'val' is your validation dataset\n",
    "        # Forward pass\n",
    "        data = item.data.float()\n",
    "        dp = item.global_path.float()\n",
    "        rel = item.local_path.float()\n",
    "        targets = item.labels.long()\n",
    "        mask = item.masks.float()\n",
    "        \n",
    "        output, p_output = model(data, dp, rel, mask)\n",
    "        prob_output = strat_model(p_output.detach())\n",
    "        strat_li.extend(prob_output.view(-1, 8).tolist())\n",
    "        _, predicted = torch.max(output.data, 2)\n",
    "        predictions.extend(predicted.view(-1).tolist())\n",
    "        true_labels.extend(targets.view(-1).tolist())\n",
    "\n",
    "    correct_predictions = sum(p == t for p, t in zip(predictions, true_labels))\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dcf5a92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:27<00:00,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    test_steps = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    strat_li = []\n",
    "    for item in tqdm(train):  # Assuming 'val' is your validation dataset\n",
    "        # Forward pass\n",
    "        data = item.data.float()\n",
    "        dp = item.global_path.float()\n",
    "        rel = item.local_path.float()\n",
    "        targets = item.labels.long()\n",
    "        mask = item.masks.float()\n",
    "        \n",
    "        output, p_output = model(data, dp, rel, mask)\n",
    "        prob_output = strat_model(p_output.detach())\n",
    "        strat_li.extend(prob_output.view(-1, 8).tolist())\n",
    "        _, predicted = torch.max(output.data, 2)\n",
    "        predictions.extend(predicted.view(-1).tolist())\n",
    "        true_labels.extend(targets.view(-1).tolist())\n",
    "\n",
    "    correct_predictions = sum(p == t for p, t in zip(predictions, true_labels))\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28fcdd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'muyixiao'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ebf3bb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b786b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 186 51\n"
     ]
    }
   ],
   "source": [
    "print(len(strat_0), len(strat_1), len(strat_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "26b5b90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.95400868e-01, 6.36767272e-04, 7.53113312e-04, 7.46094593e-04,\n",
       "       6.34061006e-04, 9.12424606e-04, 2.44664752e-04, 6.72005841e-04])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(strat_0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b1ac6e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94858803e-01, 7.32106693e-04, 9.05545767e-04, 8.02910896e-04,\n",
       "       6.92718707e-04, 1.01897926e-03, 2.84072936e-04, 7.04861574e-04])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(strat_1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce09bae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.93953057e-01, 8.51284087e-04, 1.07124628e-03, 8.79352118e-04,\n",
       "       8.53868659e-04, 1.22368976e-03, 3.41779150e-04, 8.25730062e-04])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(strat_2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c54e57b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  4.,  8.,  6., 10., 21., 30., 32., 19.,  9.]),\n",
       " array([0.99129581, 0.99194635, 0.99259688, 0.99324741, 0.99389794,\n",
       "        0.99454847, 0.995199  , 0.99584953, 0.99650006, 0.99715059,\n",
       "        0.99780113]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s00 = [item[0] for item in strat_0]\n",
    "plt.hist(s00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18dbeaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  2.,  1.,  3., 10., 16., 25., 49., 53., 24.]),\n",
       " array([0.98734868, 0.98837871, 0.98940874, 0.99043878, 0.99146881,\n",
       "        0.99249884, 0.99352888, 0.99455891, 0.99558895, 0.99661898,\n",
       "        0.99764901]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s10 = [item[0] for item in strat_1]\n",
    "plt.hist(s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9fd40961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  2.,  3.,  3.,  3., 10., 11.,  9.,  6.,  2.]),\n",
       " array([0.98864567, 0.98955172, 0.99045777, 0.99136382, 0.99226987,\n",
       "        0.99317592, 0.99408197, 0.99498802, 0.99589407, 0.99680012,\n",
       "        0.99770617]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s20 = [item[0] for item in strat_2]\n",
    "plt.hist(s20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4bb976d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13.,  72., 129., 108.,  99.,  61.,  17.,  13.,   2.,   1.]),\n",
       " array([0.07648688, 0.09734569, 0.1182045 , 0.13906332, 0.15992213,\n",
       "        0.18078094, 0.20163976, 0.22249857, 0.24335738, 0.2642162 ,\n",
       "        0.28507501]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s01 = [item[1] for item in strat_0]\n",
    "plt.hist(s01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a3e9f929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,  32.,  91., 189., 154., 108.,  39.,  24.,   1.,   2.]),\n",
       " array([0.08548212, 0.10813268, 0.13078323, 0.15343378, 0.17608434,\n",
       "        0.19873489, 0.22138545, 0.244036  , 0.26668656, 0.28933711,\n",
       "        0.31198767]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s11 = [item[1] for item in strat_1]\n",
    "plt.hist(s11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "03ba3a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  5.,  8., 11., 13.,  4.,  6.,  2.,  2.]),\n",
       " array([0.11463587, 0.12875605, 0.14287623, 0.1569964 , 0.17111658,\n",
       "        0.18523676, 0.19935694, 0.21347712, 0.22759729, 0.24171747,\n",
       "        0.25583765]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s21 = [item[1] for item in strat_2]\n",
    "plt.hist(s21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40fe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34dad735",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes, num_sequences = 0, 0\n",
    "seq_dataset = []\n",
    "arr = []\n",
    "    \n",
    "split = [64, 128]\n",
    "val = 0\n",
    "data = pkl.load(open(os.path.join(out_dir, f'{journalist}_dict.pkl'), 'rb'))\n",
    "#logging.info(f'loaded split aliceysu...')\n",
    "num_classes = 3\n",
    "num_sequences = len(set(data['conversation_id']))\n",
    "journal = pd.DataFrame.from_dict(data)\n",
    "#journal_sort = journal.sort_values(by=['created_at'])\n",
    "#journal_batch = journal_sort[[\"type\", \"possibly_sensitive\", \"lang\", \"reply_settings\",\n",
    "#                              \"retweet_count\", \"reply_count\", \"like_count\", \"quote_count\", \"impression_count\",\n",
    "#                              \"mentions\", \"urls\", \"labels\"]]\n",
    "journal_sort = pd.read_csv(os.path.join(out_dir, f'{journalist}_context.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c42f16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(set(journal_sort['conversation_id']))\n",
    "id_pair = {}\n",
    "id_conv = {}\n",
    "for idx in ids:\n",
    "    id_pair[idx], id_conv[idx] = create_conversation_list(journal_sort[journal_sort['conversation_id']==idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38d80c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_dir, f'{journalist}_global_path.txt')) as f:\n",
    "    global_path = f.readlines()\n",
    "    \n",
    "with open(os.path.join(out_dir, f'{journalist}_local_path.txt')) as f:\n",
    "    local_path = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7d71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dict = convert_path(global_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ea434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#journal_sort['global'] = [global_dict.get(str(id), global_dict[id]) for id in journal_sort['tweet_id']]\n",
    "#journal_sort.to_csv(os.path.join(out_dir, f'{journalist}_context.csv'))\n",
    "global_paths = [] # input\n",
    "id_clean = {}\n",
    "for i in ids:\n",
    "    temp = []\n",
    "    id_clean[i] = []\n",
    "    for j, item in enumerate(id_conv[i]):\n",
    "        if str(item) not in global_dict.keys():\n",
    "            continue\n",
    "        temp.append(global_dict[str(item)])\n",
    "        id_clean[i].append(item)\n",
    "    global_paths.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03fe4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(out_dir, f'{journalist}_global_path.txt'), \"w\") as fout:\n",
    "#     num_dps = 0\n",
    "#     for k in id_pair.keys():\n",
    "#         tree_root = build_tree(id_pair[k])\n",
    "        \n",
    "#         tree_root.create_global_relation()\n",
    "#         node_list = tree_root.dfs()\n",
    "\n",
    "#         root_paths = TreeNode.extract_data(node_list,f=lambda node: clamp_and_slice_ids(\n",
    "#                 node.global_relation, max_width=-1, max_depth=-1))\n",
    "#         asts = separate_dps(root_paths, n_ctx)\n",
    "\n",
    "#         \"\"\"for lr, extended in asts:\n",
    "#             if extended != 0:\n",
    "#                 break\n",
    "#             if len(lr) - extended > 1:\n",
    "#                 \"\"\"\n",
    "#         json.dump(root_paths, fp=fout)  # each line is the json of a list [dict,dict,...]\n",
    "#         num_dps += 1\n",
    "#         fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "91e06829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_dps = 0\n",
    "# with open(os.path.join(out_dir, f'{journalist}_local_path.txt'), \"w\") as fout:\n",
    "#     for k in id_pair.keys():\n",
    "#         tree_root = build_tree(id_pair[k])\n",
    "        \n",
    "#         tree_root.create_local_relation()\n",
    "#         node_list = tree_root.dfs()\n",
    "\n",
    "#         local_relation = TreeNode.extract_data(node_list,f=lambda node: clamp_and_slice_ids(\n",
    "#                 node.local_relation, max_width=-1, max_depth=-1))\n",
    "#         rel = separate_dps(local_relation, n_ctx)\n",
    "\n",
    "#         \"\"\"for lr, extended in rel:\n",
    "#             if extended != 0:\n",
    "#                 break\n",
    "#             if len(lr) - extended > 1:\"\"\"\n",
    "#         json.dump(local_relation, fp=fout)  # each line is the json of a list [dict,dict,...]\n",
    "#         num_dps += 1\n",
    "#         fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67ef66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5582b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = './result'\n",
    "journalist = 'aliceysu'\n",
    "n_ctx = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11bb1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = []\n",
    "target_data = []\n",
    "conv_data = []\n",
    "ref_data = []\n",
    "id_data = []\n",
    "for idx in ids:\n",
    "    convs = journal_sort[journal_sort['conversation_id'] == idx]\n",
    "    convs_batch = convs[[\"type\", \"possibly_sensitive\", \"lang\", \"reply_settings\",\n",
    "                     \"retweet_count\", \"reply_count\", \"like_count\", \"quote_count\", \"impression_count\",\n",
    "                     \"mentions\", \"urls\"]]\n",
    "    conv_data.append(list(convs['conversation_id']))\n",
    "    ref_data.append(list(convs['reference_id']))\n",
    "    id_data.append(list(convs['tweet_id']))\n",
    "    batch_data.append(convs_batch.values.tolist())\n",
    "    target_data.append(list(convs['labels']))\n",
    "    \n",
    "label_data = target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3890f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = []\n",
    "for i, idx in enumerate(ids):\n",
    "    tree_root = build_tree(id_pair[idx])\n",
    "    node_info = get_node_info(tree_root)\n",
    "    temp_list = []\n",
    "    #temp_list.append([node_info[idx]['level'], node_info[idx]['number_of_siblings'], node_info[idx]['sibling_order']])\n",
    "    for item in id_data[i]:\n",
    "        \"\"\"if item not in node_info.keys():\n",
    "            continue\"\"\"\n",
    "        temp_list.append([node_info[item]['level'], \n",
    "                    node_info[item]['number_of_siblings'], \n",
    "                    node_info[item]['sibling_order']])\n",
    "    position_data.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13fbd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, X_test = batch_data[:split[0]], batch_data[split[0]:split[1]], batch_data[split[1]:]\n",
    "pos_train, pos_dev, pos_test = position_data[:split[0]], position_data[split[0]:split[1]], position_data[split[1]:]\n",
    "id_train, id_dev, id_test = id_data[:split[0]], id_data[split[0]:split[1]], id_data[split[1]:]\n",
    "label_train, label_dev, label_test = label_data[:split[0]], label_data[split[0]:split[1]], label_data[split[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7f9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249f4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4b8e746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [00:00<00:00, 674.48it/s]\n",
      "100%|██████████| 419/419 [00:00<00:00, 1124.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dp = []\n",
    "with open(os.path.join(out_dir, f'{journalist}_global_path.txt'), \"r\") as f:\n",
    "    for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "        dp.append(json.loads(line.strip()))\n",
    "        \n",
    "rel = []\n",
    "with open(os.path.join(out_dir, f'{journalist}_local_path.txt'), \"r\") as f:\n",
    "    for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "        rel.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9eb82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = convert_global(dp, id_data)\n",
    "local = convert_local(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ebac96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_dir, f'{journalist}_global_path.pkl'),'wb') as f:\n",
    "    pickle.dump(roots, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e15ae513",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'4112'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-7e3dfddf3ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnew_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-236-7e3dfddf3ec5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnew_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '4112'"
     ]
    }
   ],
   "source": [
    "## test\n",
    "max_len = max(len(dp[0]) for dp in batch_data[:8])\n",
    "max_depth = 12\n",
    "max_width = 16\n",
    "seqs = (id_data[:8], batch_data[:8], roots[:8])\n",
    "r = []\n",
    "for i in range(8):\n",
    "    new_root = [roots[i][str(x)] for x in id_data[i]][:] + [[] for _ in range(max_len - len(id_data[i]))]\n",
    "    r.append(new_root)\n",
    "    \n",
    "positions = generate_positions(r[1], max_width, max_depth)\n",
    "position_seqs = []\n",
    "positions = generate_positions(r[1], max_width=max_width, max_depth=max_depth)\n",
    "position_seqs.append(positions.unsqueeze(0))\n",
    "\n",
    "position_seqs[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "710357f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/yian3/.conda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "local_mat = generate_local_mat(local, id_data)\n",
    "local_input = create_mat(local_mat, mat_type='concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b27e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc557f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17de4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907499b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4d26fd",
   "metadata": {},
   "source": [
    "## test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5534df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(journal_sort, ids):\n",
    "    batch_data = []\n",
    "    target_data = []\n",
    "    conv_data = []\n",
    "    ref_data = []\n",
    "    id_data = []\n",
    "    for idx in ids:\n",
    "        convs = journal_sort[journal_sort['conversation_id'] == idx]\n",
    "        convs_batch = convs[['type', 'possibly_sensitive', 'lang', 'reply_settings', \n",
    "                               'retweet_count', 'reply_count', 'like_count', 'quote_count',\n",
    "                                'impression_count', 'mentions', 'urls']]\n",
    "        #conv_data.append(list(convs['conversation_id']))\n",
    "        conv_data.append(convs_batch.to_numpy().tolist())\n",
    "        ref_data.append(list(convs['reference_id']))\n",
    "        id_data.append(list(convs['tweet_id']))\n",
    "        batch_data.append(convs_batch.values.tolist())\n",
    "        target_data.append(list(convs['labels']))\n",
    "    \n",
    "    label_data = target_data\n",
    "    return id_data, conv_data, label_data\n",
    "\n",
    "def load_data(data_dir, journalist, classes, batch_size, collate):\n",
    "    ### Data (normalize input inter-event times, then padding to create dataloaders)\n",
    "    num_classes, num_sequences = 0, 0\n",
    "    seq_dataset = []\n",
    "    arr = []\n",
    "    dp = []\n",
    "    rel = []\n",
    "    \n",
    "    split = [64, 128]\n",
    "    val = 0\n",
    "    journal_sort = pd.read_csv((os.path.join(data_dir, f'{journalist}_context.csv')))\n",
    "    ids = list(set(journal_sort['conversation_id']))\n",
    "    id_pair = {}\n",
    "    id_conv = {}\n",
    "    for idx in ids:\n",
    "        id_pair[idx], id_conv[idx] = create_conversation_list(journal_sort[journal_sort['conversation_id']==idx], idx)\n",
    "    id_data, data, label = create_data(journal_sort, ids)\n",
    "    prob = pkl.load(open(os.path.join(data_dir, f'{journalist}_edgeprob.pkl'), 'rb'))\n",
    "    \n",
    "    with open(os.path.join(data_dir, f'{journalist}_global_path.txt'), \"r\") as f:\n",
    "        for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "            dp.append(json.loads(line.strip()))\n",
    "\n",
    "    with open(os.path.join(data_dir, f'{journalist}_local_path.txt'), \"r\") as f:\n",
    "        for line in tqdm(f, total=get_number_of_lines(f)):\n",
    "            rel.append(json.loads(line.strip()))\n",
    "    \n",
    "    global_input = convert_global(dp, id_data)\n",
    "    local_data = convert_local(rel)\n",
    "    local_mat = generate_local_mat(local_data, id_data)\n",
    "    local_input = create_mat(local_mat, mat_type='concat')\n",
    "    logging.info(f'loaded split {journalist}...')\n",
    "    # data - dict: dim_process, devtest, args, train, dev, test, index (train/dev/test given as)\n",
    "    # data[split] - list dicts {'time_since_start': at, 'time_since_last_event': dt, 'type_event': mark} or\n",
    "    # data[split] - dict {'arrival_times', 'delta_times', 'marks'}\n",
    "    # data['dim_process'] = Number of accounts = 119,298\n",
    "    # num_sequences: number of conversations of a journalist\n",
    "    num_classes = classes\n",
    "    #num_sequences += len(data[split]['arrival_times'])\n",
    "    num_sequences = len(set(journal_sort['conversation_id']))\n",
    "    \n",
    "    X_train, X_dev, X_test = data[:split[0]], data[split[0]:split[1]], data[split[1]:]\n",
    "    prob_train, prob_dev, prob_test = prob[:split[0]], prob[split[0]:split[1]], prob[split[1]:]\n",
    "    global_train, global_dev, global_test = global_input[:split[0]], global_input[split[0]:split[1]], global_input[split[1]:]\n",
    "    local_train, local_dev, local_test = local_input[:split[0]], local_input[split[0]:split[1]], local_input[split[1]:]\n",
    "    label_train, label_dev, label_test = label[:split[0]], label[split[0]:split[1]], label[split[1]:]\n",
    "\n",
    "    d_train = TreeDataset(X_train, prob_train, global_train, local_train, label_train)\n",
    "    d_val = TreeDataset(X_dev, prob_dev, global_dev, local_dev, label_dev)  \n",
    "    d_test  = TreeDataset(X_test, prob_test, global_test, local_test, label_test)   \n",
    "\n",
    "    # for padding input sequences to maxlen of batch for running on gpu, and arranging them by length efficient\n",
    "    collate = collate  \n",
    "    dl_train = torch.utils.data.DataLoader(d_train, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "    dl_val = torch.utils.data.DataLoader(d_val, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "    dl_test = torch.utils.data.DataLoader(d_test, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "    return dl_train, dl_val, dl_test\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNodes:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = []  # List of TreeNode objects\n",
    "        self.level = 0  # Level of the node in the tree\n",
    "        self.sibling_order = 0  # Order among siblings\n",
    "        self.parent = None  # Parent of the node\n",
    "        self.local_relation = dict()\n",
    "        self.global_relation = dict()\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        child_node.parent = self\n",
    "        child_node.level = self.level + 1 if self.level is not None else 0\n",
    "        child_node.sibling_order = len(self.children)\n",
    "        self.children.append(child_node)\n",
    "\n",
    "    def num_siblings(self):\n",
    "        return len(self.parent.children)-1 if self.parent else 0\n",
    "    \n",
    "    def extract_data(node_list, only_leaf=False, f=lambda node: node.data):\n",
    "        ret = []\n",
    "        #print(\"?\")\n",
    "        for node in node_list:\n",
    "            if not (only_leaf and node.node_type == \"type\"):\n",
    "                ret.append({node.name: f(node)})\n",
    "        return ret\n",
    "\n",
    "    def create_local_relation(self):\n",
    "\n",
    "        def _dfs(node):\n",
    "            for child in node.children:\n",
    "                node_child_rel = [child.level, child.num_siblings(), child.sibling_order]\n",
    "                node_father_rel = [node.level, node.num_siblings(), node.sibling_order]\n",
    "                #node_father_rel = child.parent\n",
    "                node.local_relation[child.name] = [node_child_rel, node_father_rel, 0]\n",
    "                child.local_relation[node.name] = [node_child_rel, node_father_rel, 1]\n",
    "                _dfs(child)\n",
    "\n",
    "        _dfs(self)\n",
    "\n",
    "    def create_global_relation(self):\n",
    "        def g_dfs(node):\n",
    "            node_rel = [node.level, node.num_siblings(), node.sibling_order]\n",
    "            if not node.parent:\n",
    "                node.global_relation[node.name] = [node_rel]\n",
    "            else: \n",
    "                if node.parent.name not in node.parent.global_relation.keys():\n",
    "                    node.global_relation[node.name] = node.parent.parent.global_relation[node.parent.parent.name] + [node_rel]\n",
    "                else:\n",
    "                    node.global_relation[node.name] = node.parent.global_relation[node.parent.name] + [node_rel]\n",
    "            for child in node.children:\n",
    "                g_dfs(child)\n",
    "\n",
    "        g_dfs(self)\n",
    " \n",
    "\n",
    "    def dfs(self):\n",
    "        ret = []\n",
    "\n",
    "        def _dfs(node, ret):\n",
    "           #ret : List\n",
    "            ret.append(node)\n",
    "            for child in node.children:\n",
    "                _dfs(child, ret)\n",
    "\n",
    "        _dfs(self, ret)\n",
    "        return ret\n",
    "    \n",
    "def build_tree(conversations):\n",
    "    nodes = {}\n",
    "    root = 0\n",
    "\n",
    "    for parent, child in conversations:\n",
    "        if parent not in nodes:\n",
    "            nodes[parent] = TreeNodes(parent)\n",
    "        if child not in nodes:\n",
    "            nodes[child] = TreeNodes(child)\n",
    "\n",
    "        nodes[parent].add_child(nodes[child])\n",
    "\n",
    "        if not root:\n",
    "            root = nodes[parent]\n",
    "\n",
    "    return root\n",
    "\n",
    "\n",
    "def separate_dps(ast, max_len):\n",
    "    \"\"\"\n",
    "    Handles training / evaluation on long ASTs by splitting\n",
    "    them into smaller ASTs of length max_len, with a sliding\n",
    "    window of max_len / 2.\n",
    "\n",
    "    Example: for an AST ast with length 1700, and max_len = 1000,\n",
    "    the output will be:\n",
    "    [[ast[0:1000], 0], [ast[500:1500], 1000], [ast[700:1700], 1500]]\n",
    "\n",
    "    Input:\n",
    "        ast : List[Dictionary]\n",
    "            List of nodes in pre-order traversal.\n",
    "        max_len : int\n",
    "\n",
    "    Output:\n",
    "        aug_asts : List[List[List, int]]\n",
    "            List of (ast, beginning idx of unseen nodes)\n",
    "    \"\"\"\n",
    "    half_len = int(max_len / 2)\n",
    "    if len(ast) <= max_len:\n",
    "        return [[ast, 0]]\n",
    "\n",
    "    aug_asts = [[ast[:max_len], 0]]\n",
    "    i = half_len\n",
    "    while i < len(ast) - max_len:\n",
    "        aug_asts.append([ast[i: i + max_len], half_len])\n",
    "        i += half_len\n",
    "    idx = max_len - (len(ast) - (i + half_len))\n",
    "    aug_asts.append([ast[-max_len:], idx])\n",
    "\n",
    "    return aug_asts\n",
    "\n",
    "\n",
    "def separate_lrs(lrs, max_len):\n",
    "    def reformat(lrs, left):  # [left,right)\n",
    "        new_lrs = []\n",
    "        for idx, lr in enumerate(lrs):\n",
    "            # lr -> dict: {idx:[],idx:[]}\n",
    "            temp_lr = dict()\n",
    "            for key, val in lr.items():\n",
    "                if left <= key < left + max_len:\n",
    "                    temp_lr[key - left] = val\n",
    "            new_lrs.append(temp_lr)\n",
    "        return new_lrs\n",
    "\n",
    "    half_len = int(max_len / 2)\n",
    "    if len(lrs) <= max_len:\n",
    "        return [[reformat(lrs, 0), 0]]\n",
    "\n",
    "    aug_asts = [[reformat(lrs[:max_len], 0), 0]]\n",
    "    i = half_len\n",
    "    while i < len(lrs) - max_len:\n",
    "        aug_asts.append([reformat(lrs[i: i + max_len], i), half_len])\n",
    "        i += half_len\n",
    "    idx = max_len - (len(lrs) - (i + half_len))\n",
    "    aug_asts.append([reformat(lrs[len(lrs) - max_len:], len(lrs) - max_len), idx])\n",
    "    return aug_asts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9738300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_global(root_paths, id_data):\n",
    "    roots = []\n",
    "    global_new = []\n",
    "    for i in range(len(root_paths)):\n",
    "        new_dict = {}\n",
    "        for item in root_paths[i]:\n",
    "            name = list(item.keys())[0]\n",
    "            new_dict[name] = np.array(list(list(item.values())[0].values())).squeeze().tolist()\n",
    "        roots.append(new_dict)\n",
    "    for i in range(len(id_data)):\n",
    "        global_new.append([roots[i][str(k)] for k in id_data[i]])\n",
    "    return global_new\n",
    "\n",
    "\n",
    "def convert_local(local_rel):\n",
    "    rel = []\n",
    "    for i in range(len(local_rel)):\n",
    "        new_dict = {}\n",
    "        for item in local_rel[i]:\n",
    "            name = list(item.keys())[0]\n",
    "            new_dict[name] = item[name]\n",
    "        rel.append(new_dict)\n",
    "    return rel\n",
    "\n",
    "def indexing(ls):\n",
    "    dic = {}\n",
    "    for i in range(len(ls)):\n",
    "        dic[ls[i]] = i\n",
    "        i += 1\n",
    "    return dic\n",
    "\n",
    "def generate_local_mat(local, idx):\n",
    "    mat = []\n",
    "    for ids, item in enumerate(local):\n",
    "        #print(ids)\n",
    "        temp = []\n",
    "        ind = indexing(idx[ids])\n",
    "        for i in idx[ids]:\n",
    "            if str(i) not in list(local[ids].keys()):\n",
    "                continue\n",
    "            for k in list(local[ids][str(i)].keys()):\n",
    "                if k == list(local[ids].keys())[0]:\n",
    "                    temp_l = local[ids][str(i)][k]\n",
    "                    temp_ind = ind[i]\n",
    "                    temp.append([temp_ind, temp_ind, temp_l[temp_l[2]]])\n",
    "                elif int(k) not in idx[ids]:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp_l = local[ids][str(i)][k]\n",
    "                    temp_ind1 = ind[i]\n",
    "                    temp_ind2 = ind[int(k)]\n",
    "                    temp.append([temp_ind1, temp_ind2, temp_l[temp_l[2]]])\n",
    "        if not temp:\n",
    "            for i in idx[ids]:\n",
    "                temp_ind = ind[i]\n",
    "                temp.append([temp_ind, temp_ind, [0, 0, 0]])\n",
    "        mat.append(temp)\n",
    "    return mat\n",
    "def create_mat(local_mat, mat_type):\n",
    "    result = []\n",
    "    for ind, item in enumerate(local_mat):\n",
    "        max_row = max(i[0] for i in item)+1\n",
    "        max_col = max(i[1] for i in item)+1\n",
    "        if mat_type == 'sum':\n",
    "            row = np.array(item)[:,0]\n",
    "            col = np.array(item)[:,1]\n",
    "\n",
    "            # taking data \n",
    "            data = np.array([sum(np.array(i)[2]) for i in item])\n",
    "\n",
    "            # creating sparse matrix \n",
    "            sparseMatrix = csr_matrix((data, (row, col)), shape = (dim, dim)).toarray() \n",
    "            result.append(sparseMatrix)\n",
    "        else:\n",
    "            matrix = np.zeros((max_row, max_col, 3), dtype=float)\n",
    "            for x in item:\n",
    "                row, col, value = x\n",
    "                matrix[row, col] = [i + 0.05 for i in value]\n",
    "            result.append(matrix)\n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95dd877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_labels(labels, max_dim, pad_token=0):\n",
    "    \"\"\"Pad the label sequence to the maximum length.\"\"\"\n",
    "    max_length = max(len(seq) for seq in labels)\n",
    "    if max_dim is not None and max_length > max_dim:\n",
    "        max_length = max_dim\n",
    "        \n",
    "    return np.array([np.pad(seq, (0, max_length - len(seq)), mode='constant', constant_values=pad_token) \n",
    "                                 for seq in labels])\n",
    "\n",
    "def pad_matrix(path, max_dim=None, pad_token=0):\n",
    "    \"\"\"Pad a 2D matrix to the specified max_length.\"\"\"\n",
    "    max_length = max(matrix.shape[0] for matrix in path)\n",
    "    if max_dim is not None and max_length > max_dim:\n",
    "        max_length = max_dim\n",
    "        \n",
    "    padded_matrices = []\n",
    "    for matrix in path:\n",
    "        truncated_matrix = matrix[:max_length, :max_length, :]\n",
    "        padding = ((0, max(0, max_length - truncated_matrix.shape[0])), \n",
    "                   (0, max(0, max_length - truncated_matrix.shape[1])), \n",
    "                   (0, 0))\n",
    "        adjusted_matrix = np.pad(truncated_matrix, pad_width=padding, mode='constant', constant_values=pad_token)\n",
    "        padded_matrices.append(adjusted_matrix)\n",
    "\n",
    "    return padded_matrices\n",
    "\n",
    "def summ(paths):\n",
    "    return [[list(map(sum, zip(*sub))) for sub in outer] for outer in paths]\n",
    "\n",
    "\n",
    "class Batch():\n",
    "    def __init__(self, data, labels, prob, global_path, local_path, masks):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prob = prob\n",
    "        self.global_path = global_path\n",
    "        self.local_path = local_path\n",
    "        self.masks = masks\n",
    "\n",
    "def pad_sequences(sequences, max_dim=None, pad_token=0):\n",
    "    # Determine the maximum sequence length\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    if max_dim is not None and max_length > max_dim:\n",
    "        max_length = max_dim\n",
    "\n",
    "    # Pad each sequence to the maximum length\n",
    "    temp_seq = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) >= max_length:\n",
    "            temp_seq.append(seq[:max_length])\n",
    "        else:\n",
    "            temp_seq.append(seq)\n",
    "    padded_sequences = np.array([np.pad(seq, ((0, max_length - len(seq)), (0, 0)), \n",
    "                                        mode='constant', constant_values=pad_token) \n",
    "                                 for seq in temp_seq])\n",
    "\n",
    "    # Create attention masks\n",
    "    attention_masks = np.array([[1 if token.any() else 0 for token in seq] \n",
    "                                for seq in padded_sequences])\n",
    "    \n",
    "    return padded_sequences, attention_masks\n",
    "\n",
    "def collate(batch):\n",
    "    batch_li = [list(item) for item in batch]\n",
    "    data_temp = [row[0] for row in batch_li]\n",
    "    labels_temp = [torch.Tensor(row[1]) for row in batch_li]\n",
    "    prob_temp = [torch.Tensor(row[2]) for row in batch_li]\n",
    "    global_path_temp = [row[3] for row in batch_li]\n",
    "    local_path_temp = [row[4] for row in batch_li]\n",
    "    \n",
    "\n",
    "    padded_data, masks = pad_sequences(data_temp, max_dim=2000, pad_token=0)\n",
    "    #padded_labels = pad_labels(labels_temp, max_dim=2000, pad_token=0)\n",
    "    #padded_prob, _ = pad_sequences(prob_temp, max_dim=2000, pad_token=0)\n",
    "    padded_global, _ = pad_sequences(summ(global_path_temp), max_dim=2000, pad_token=0)\n",
    "    padded_local = pad_matrix(local_path_temp, max_dim=2000, pad_token=0)\n",
    "\n",
    "    data= torch.tensor(padded_data).to(torch.int64)\n",
    "    #labels = torch.tensor(padded_labels).to(torch.int64)\n",
    "    #prob = torch.tensor(padded_prob).to(torch.int64)\n",
    "    global_path = torch.tensor(padded_global).to(torch.int64)\n",
    "    local_path = torch.tensor(padded_local).to(torch.int64)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels_temp, batch_first=True)\n",
    "    prob = torch.nn.utils.rnn.pad_sequence(prob_temp, batch_first=True)\n",
    "    #global_path = torch.nn.utils.rnn.pad_sequence(global_path_temp, batch_first=True)\n",
    "    #local_path = torch.nn.utils.rnn.pad_sequence(local_path_temp, batch_first=True)\n",
    "    #print(masks)\n",
    "    \n",
    "    #out_tweet_type = torch.nn.utils.rnn.pad_sequence(out_tweet_types, batch_first=True)\n",
    "    #print(\"start\")\n",
    "    return Batch(data, labels, prob, global_path, local_path, torch.tensor(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = []  # List of TreeNode objects\n",
    "        self.level = 0  # Level of the node in the tree\n",
    "        self.sibling_order = 0  # Order among siblings\n",
    "        self.parent = None  # Parent of the node\n",
    "        self.local_relation = dict()\n",
    "        self.global_relation = dict()\n",
    "        \n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        child_node.parent = self\n",
    "        child_node.level = self.level + 1 if self.level is not None else 0\n",
    "        child_node.sibling_order = len(self.children)\n",
    "        self.children.append(child_node)\n",
    "\n",
    "    def num_siblings(self):\n",
    "        return len(self.parent.children)-1 if self.parent else 0\n",
    "    \n",
    "    def extract_data(node_list, only_leaf=False, f=lambda node: node.data):\n",
    "        ret = []\n",
    "        for node in node_list:\n",
    "            if not (only_leaf and node.node_type == \"type\"):\n",
    "                ret.append(f(node))\n",
    "        return ret\n",
    "\n",
    "    def create_local_relation(self):\n",
    "        def _dfs(node):\n",
    "            for child in node.children:\n",
    "                node_child_rel = [child.level, child.num_siblings(), child.sibling_order]\n",
    "                node_father_rel = [node.level, node.num_siblings(), node.sibling_order]\n",
    "                \n",
    "                node.local_relation[child.name] = [node_child_rel, node_father_rel, 0]\n",
    "                child.local_relation[node.name] = [node_child_rel, node_father_rel, 1]\n",
    "                _dfs(child)\n",
    "\n",
    "        _dfs(self)\n",
    "    \n",
    "    def create_global_relation(self):\n",
    "        def g_dfs(node):\n",
    "            node_rel = [node.level, node.num_siblings(), node.sibling_order]\n",
    "            if not node.parent:\n",
    "                node.global_relation[node.name] = [node_rel]\n",
    "            else: \n",
    "                if node.parent.name not in node.parent.global_relation.keys():\n",
    "                    node.global_relation[node.name] = node.parent.parent.global_relation[node.parent.parent.name] + [node_rel]\n",
    "                else:\n",
    "                    node.global_relation[node.name] = node.parent.global_relation[node.parent.name] + [node_rel]\n",
    "            for child in node.children:\n",
    "                g_dfs(child)\n",
    "\n",
    "        g_dfs(self)\n",
    "        #return \n",
    "\n",
    "    def dfs(self):\n",
    "        ret = []\n",
    "\n",
    "        def _dfs(node, ret):\n",
    "           #ret : List\n",
    "            ret.append(node)\n",
    "            for child in node.children:\n",
    "                _dfs(child, ret)\n",
    "\n",
    "        _dfs(self, ret)\n",
    "        return ret\n",
    "    \n",
    "def build_tree(conversations):\n",
    "    nodes = {}\n",
    "    root = 0\n",
    "\n",
    "    for parent, child in conversations:\n",
    "        if parent not in nodes:\n",
    "            nodes[parent] = TreeNode(parent)\n",
    "        if child not in nodes:\n",
    "            nodes[child] = TreeNode(child)\n",
    "        nodes[parent].add_child(nodes[child])\n",
    "\n",
    "        if not root:\n",
    "            root = nodes[parent]\n",
    "\n",
    "    return root\n",
    "\n",
    "def get_node_info(tree_root):\n",
    "    node_info = {}\n",
    "\n",
    "    def traverse(node):\n",
    "        node_info[node.name] = {\n",
    "            'level': node.level,\n",
    "            'number_of_siblings': node.num_siblings(),\n",
    "            'sibling_order': node.sibling_order,\n",
    "        }\n",
    "        for child in node.children:\n",
    "            traverse(child)\n",
    "\n",
    "    traverse(tree_root)\n",
    "    return node_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d6bc5",
   "metadata": {},
   "source": [
    "## Mukhil's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca61587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aliceysu\n",
    "# bainjal\n",
    "users = []\n",
    "journalist = 'aliceysu'\n",
    "user_id = '24709718'\n",
    "data_dir = '../desktop/'\n",
    "path = os.path.join(data_dir, f'tweets_in_{journalist}_started_convs.json')\n",
    "# '../desktop/tweets_in_aliceysu_started_convs.json'\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        users.append(json.loads(line))\n",
    "    #users = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c40f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n"
     ]
    }
   ],
   "source": [
    "data = users[0]\n",
    "user_ids = set()\n",
    "for i in range(len(data)):  \n",
    "    user_ids.add(data[i]['conversation_id'])\n",
    "print(len(user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2f2ce8e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'possibly_sensitive': False,\n",
       " 'lang': 'qme',\n",
       " 'conversation_id': '1603565869673873408',\n",
       " 'referenced_tweets': [{'type': 'replied_to', 'id': '1603565869673873408'}],\n",
       " 'edit_history_tweet_ids': ['1608261522870136833'],\n",
       " 'reply_settings': 'everyone',\n",
       " 'created_at': '2022-12-29T00:40:01.000Z',\n",
       " 'public_metrics': {'retweet_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 0,\n",
       "  'quote_count': 0,\n",
       "  'impression_count': 3},\n",
       " 'entities': {'urls': [{'start': 10,\n",
       "    'end': 33,\n",
       "    'url': 'https://t.co/stR6weHTUO',\n",
       "    'expanded_url': 'https://rumble.com/v21y3qs-covid-19-vaccines-what-they-are-how-they-work-and-possible-causes-of-injuri.html',\n",
       "    'display_url': 'rumble.com/v21y3qs-covid-…',\n",
       "    'images': [{'url': 'https://pbs.twimg.com/news_img/1623388282397630467/SN1aV-kE?format=jpg&name=orig',\n",
       "      'width': 1280,\n",
       "      'height': 720},\n",
       "     {'url': 'https://pbs.twimg.com/news_img/1623388282397630467/SN1aV-kE?format=jpg&name=150x150',\n",
       "      'width': 150,\n",
       "      'height': 150}],\n",
       "    'status': 200,\n",
       "    'title': \"VSRF Reports: Highlights & exclusive interview footage with key doctors & speakers at Sen. Ron Johnson's Covid-19 Vaccine Roundtable\",\n",
       "    'description': \"Investigative journalist, Dan Cohen, interviewed key doctors and speakers for VSRF, for this 25 minute highlight reel which features both testimony and individual interviews from Senator Johnson's Rou\",\n",
       "    'unwound_url': 'https://rumble.com/v21y3qs-covid-19-vaccines-what-they-are-how-they-work-and-possible-causes-of-injuri.html'}],\n",
       "  'mentions': [{'start': 0,\n",
       "    'end': 9,\n",
       "    'username': 'aliceysu',\n",
       "    'id': '24709718'}]},\n",
       " 'in_reply_to_user_id': '24709718',\n",
       " 'text': '@aliceysu https://t.co/stR6weHTUO',\n",
       " 'edit_controls': {'edits_remaining': 5,\n",
       "  'is_edit_eligible': False,\n",
       "  'editable_until': '2022-12-29T01:10:01.000Z'},\n",
       " 'id': '1608261522870136833',\n",
       " 'author_id': '1519143967886954496'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35a14cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6925\n",
      "10685\n"
     ]
    }
   ],
   "source": [
    "people = set()\n",
    "tweets = []\n",
    "for i in range(len(data)):\n",
    "    if (data[i]['conversation_id'] in user_ids):\n",
    "        people.add(data[i]['author_id'])\n",
    "        tweets.append(data[i]['author_id'])\n",
    "print(len(people))\n",
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6864a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### INITIALISAING ACTIVITY TRACE DICTIONARY #########\n",
    "activity_traces = {}\n",
    "for element in user_ids:\n",
    "    activity_traces[element] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b30e6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 12, 29, 0, 40, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_format = \"%Y-%m-%dT%H:%M:%S\" \n",
    "datetime.strptime(data[0]['created_at'][:19], date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4efeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "######### ACCUMLATING TWEETS UNDER THEIR CONVERSATION ID #########\n",
    "count = 0\n",
    "for i in range(len(data)):\n",
    "    conversation_id = data[i]['conversation_id']\n",
    "    if conversation_id in user_ids:\n",
    "        if 'referenced_tweets' in data[i]:\n",
    "            if data[i]['referenced_tweets'][0]['type'] == 'replied_to':\n",
    "                if [data[i]['id'], datetime.strptime(data[i]['created_at'][:19], date_format), data[i]['author_id'], 1] in activity_traces[conversation_id]:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    activity_traces[conversation_id].append([data[i]['id'], datetime.strptime(data[i]['created_at'][:19], date_format), data[i]['author_id'], 1])\n",
    "            elif data[i]['referenced_tweets'][0]['type'] == 'quoted':\n",
    "                if [data[i]['id'], datetime.strptime(data[i]['created_at'][:19], date_format), data[i]['author_id'], 2] in activity_traces[conversation_id]:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    activity_traces[conversation_id].append([data[i]['id'], datetime.strptime(data[i]['created_at'][:19], date_format), data[i]['author_id'], 2])\n",
    "        else:\n",
    "            if [data[i]['id'], datetime.strptime(data[i]['created_at'][:19], date_format), data[i]['author_id'], 0] in activity_traces[conversation_id]:\n",
    "                count += 1\n",
    "            else:\n",
    "                activity_traces[conversation_id].append([data[i]['id'], datetime.strptime(data[i]['created_at'][:19], date_format), data[i]['author_id'], 0])\n",
    "            \n",
    "# 0 for original tweet, 1 for reply to another tweet, 2 for quoted tweet.\n",
    "# 54607 duplicated\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009eccfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1608261522870136833',\n",
       "  datetime.datetime(2022, 12, 29, 0, 40, 1),\n",
       "  '1519143967886954496',\n",
       "  1],\n",
       " ['1603751795553361921',\n",
       "  datetime.datetime(2022, 12, 16, 13, 59, 58),\n",
       "  '2411054094',\n",
       "  1],\n",
       " ['1603566654969245696',\n",
       "  datetime.datetime(2022, 12, 16, 1, 44, 18),\n",
       "  '51081835',\n",
       "  1]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_traces['1603565869673873408']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c411e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### SORTING WITHIN AN ACTIVITY TRACE BASED ON TIME #########\n",
    "sorted_activity_trace_dirty = []\n",
    "for key in activity_traces:\n",
    "    sorted_activity_trace_dirty.append(sorted(activity_traces[key], key=lambda d: d[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa48a5b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######### REMOVING ACTIVITY TRACES THAT ARE OF LENGTH ONE OR LESS #########\n",
    "index = []\n",
    "sorted_activity_trace = []\n",
    "for i in range(len(sorted_activity_trace_dirty)):\n",
    "    if len(sorted_activity_trace_dirty[i]) > 1:\n",
    "        sorted_activity_trace.append(sorted_activity_trace_dirty[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f944d2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_activity_trace_dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e94b48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CREATING USER ID MAPPING AND THE REVERSE MAPPING TO OBTAIN INPUT MARKS VALUES AND DECODE THEM #########\n",
    "ents = []\n",
    "for actTrace in sorted_activity_trace:\n",
    "    for act in actTrace:\n",
    "        ents.append(act[2])\n",
    "\n",
    "idmap = {}\n",
    "other_way = {}\n",
    "for idx, ent in enumerate(set(ents)):\n",
    "    idmap[ent] = idx\n",
    "    other_way[idx] = ent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dadb292",
   "metadata": {},
   "outputs": [],
   "source": [
    "numTraces = len(sorted_activity_trace)\n",
    "\n",
    "np.random.shuffle(sorted_activity_trace)\n",
    "\n",
    "valTraces = sorted_activity_trace[:int(0.1*numTraces)]\n",
    "testTraces = sorted_activity_trace[int(0.1*numTraces):int(0.2*numTraces)]\n",
    "trainTraces = sorted_activity_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a6c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = {}\n",
    "cols = ['arrival_times', 'delta_times', 'marks', 'tweet_type']\n",
    "\n",
    "for col in cols:\n",
    "    split[col] = []\n",
    "\n",
    "tweetSeqMap = {}\n",
    "lengths = []\n",
    "\n",
    "for idx, activityTrace in enumerate(trainTraces): \n",
    "    #assert int(activityTrace[0][2]) == userId\n",
    "    \n",
    "    starts = [act[1] for act in activityTrace]\n",
    "    iStart = starts[0]\n",
    "    \n",
    "    normStarts = [ (act[1] - iStart).total_seconds()/(24*3600) for act in activityTrace]\n",
    "    assert normStarts[0] == 0\n",
    "    deltaTimes = [1.0] \n",
    "    for i in range(1,len(normStarts)):\n",
    "        deltaTimes.append(normStarts[i] - normStarts[i-1] )\n",
    "        \n",
    "    marks = []\n",
    "    for i in range(len(normStarts)):\n",
    "        marks.append(idmap[activityTrace[i][2]])\n",
    "    \n",
    "    tweet_type = []\n",
    "    for i in range(len(normStarts)):\n",
    "        tweet_type.append(activityTrace[i][3])\n",
    "        \n",
    "    tweetSeqMap[activityTrace[0][0]] = idx\n",
    "    lengths.append(len(normStarts))\n",
    "    split['arrival_times'].append(normStarts)\n",
    "    split['delta_times'].append(deltaTimes)\n",
    "    split['marks'].append(marks)\n",
    "    split['tweet_type'].append(tweet_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54b3d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split1 = {}\n",
    "for col in cols:\n",
    "    split1[col] = []\n",
    "for idx, activityTrace in enumerate(testTraces): \n",
    "    #assert int(activityTrace[0][2]) == userId\n",
    "    \n",
    "    starts = [act[1] for act in activityTrace]\n",
    "    iStart = starts[0]\n",
    "    \n",
    "    normStarts = [ (act[1] - iStart).total_seconds()/(24*3600) for act in activityTrace]\n",
    "    assert normStarts[0] == 0\n",
    "    deltaTimes = [1.0] \n",
    "    for i in range(1,len(normStarts)):\n",
    "        deltaTimes.append( normStarts[i] - normStarts[i-1] )\n",
    "        \n",
    "    marks = []\n",
    "    for i in range(len(normStarts)):\n",
    "        marks.append(idmap[activityTrace[i][2]])\n",
    "        \n",
    "    tweet_type = []\n",
    "    for i in range(len(normStarts)):\n",
    "        tweet_type.append(activityTrace[i][3])\n",
    "        \n",
    "    tweetSeqMap[activityTrace[0][0]] = idx\n",
    "    \n",
    "    split1['arrival_times'].append(normStarts)\n",
    "    split1['delta_times'].append(deltaTimes)\n",
    "    split1['marks'].append(marks)\n",
    "    split1['tweet_type'].append(tweet_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "657feab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split2 = {}\n",
    "\n",
    "for col in cols:\n",
    "    split2[col] = []\n",
    "for idx, activityTrace in enumerate(valTraces): \n",
    "    #assert int(activityTrace[0][2]) == userId\n",
    "    \n",
    "    starts = [act[1] for act in activityTrace]\n",
    "    iStart = starts[0]\n",
    "    \n",
    "    normStarts = [ (act[1] - iStart).total_seconds()/(24*3600) for act in activityTrace]\n",
    "    assert normStarts[0] == 0\n",
    "    deltaTimes = [1.0] \n",
    "    for i in range(1,len(normStarts)):\n",
    "        deltaTimes.append( normStarts[i] - normStarts[i-1] )\n",
    "        \n",
    "    marks = []\n",
    "    for i in range(len(normStarts)):\n",
    "        marks.append(idmap[activityTrace[i][2]])\n",
    "        \n",
    "    tweet_type = []\n",
    "    for i in range(len(normStarts)):\n",
    "        tweet_type.append(activityTrace[i][3])\n",
    "    tweetSeqMap[activityTrace[0][0]] = idx\n",
    "\n",
    "    split2['arrival_times'].append(normStarts)\n",
    "    split2['delta_times'].append(deltaTimes)\n",
    "    split2['marks'].append(marks)\n",
    "    split2['tweet_type'].append(tweet_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7533e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result = {}\n",
    "data_result[\"train\"] = split\n",
    "data_result[\"test\"] = split1\n",
    "data_result[\"dev\"] = split2\n",
    "data_result['dim_process'] = len(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4612f575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arrival_times': [[0.0, 2.527210648148148],\n",
       "  [0.0, 0.0014467592592592592],\n",
       "  [0.0, 0.03166666666666667, 30.01508101851852, 437.3130092592593],\n",
       "  [0.0, 0.14180555555555555],\n",
       "  [0.0,\n",
       "   0.006423611111111111,\n",
       "   0.01766203703703704,\n",
       "   0.02746527777777778,\n",
       "   0.07740740740740741,\n",
       "   0.08822916666666666,\n",
       "   0.19037037037037038,\n",
       "   0.4257523148148148,\n",
       "   0.5247685185185185,\n",
       "   0.5637152777777777,\n",
       "   0.66875,\n",
       "   1.6597337962962964,\n",
       "   1.6610763888888889,\n",
       "   1.7932291666666667],\n",
       "  [0.0,\n",
       "   0.09506944444444444,\n",
       "   0.3719675925925926,\n",
       "   0.421875,\n",
       "   0.8337037037037037,\n",
       "   1.1365277777777778,\n",
       "   3.1604282407407407,\n",
       "   3.6797569444444442,\n",
       "   6.233449074074074],\n",
       "  [0.0, 0.22703703703703704, 1.990324074074074, 2.297083333333333],\n",
       "  [0.0,\n",
       "   0.0030555555555555557,\n",
       "   0.3507986111111111,\n",
       "   0.6315046296296296,\n",
       "   2.8250462962962963],\n",
       "  [0.0,\n",
       "   0.0012731481481481483,\n",
       "   0.004340277777777778,\n",
       "   0.005613425925925926,\n",
       "   0.012326388888888888,\n",
       "   0.01238425925925926,\n",
       "   0.014293981481481482,\n",
       "   0.014421296296296297,\n",
       "   0.01670138888888889,\n",
       "   0.018703703703703705,\n",
       "   0.020277777777777777,\n",
       "   0.0259375,\n",
       "   0.026828703703703705,\n",
       "   0.027141203703703702,\n",
       "   0.03224537037037037,\n",
       "   0.03497685185185185,\n",
       "   0.04017361111111111,\n",
       "   0.048414351851851854,\n",
       "   0.36212962962962963,\n",
       "   0.3629398148148148,\n",
       "   0.6933333333333334],\n",
       "  [0.0, 1.2914467592592593],\n",
       "  [0.0,\n",
       "   0.0014583333333333334,\n",
       "   0.12026620370370371,\n",
       "   0.18835648148148149,\n",
       "   0.2044675925925926],\n",
       "  [0.0,\n",
       "   0.07358796296296297,\n",
       "   0.07893518518518519,\n",
       "   0.0999537037037037,\n",
       "   0.12357638888888889,\n",
       "   0.13644675925925925,\n",
       "   0.16424768518518518,\n",
       "   0.17622685185185186,\n",
       "   0.21410879629629628,\n",
       "   0.21920138888888888,\n",
       "   0.2576041666666667,\n",
       "   0.4295949074074074,\n",
       "   0.435,\n",
       "   0.44600694444444444,\n",
       "   0.4505439814814815,\n",
       "   0.48703703703703705,\n",
       "   0.8718402777777777,\n",
       "   2.0133564814814813,\n",
       "   2.880138888888889],\n",
       "  [0.0,\n",
       "   0.0028587962962962963,\n",
       "   0.01923611111111111,\n",
       "   0.026608796296296297,\n",
       "   0.027997685185185184,\n",
       "   0.031747685185185184,\n",
       "   0.03234953703703704,\n",
       "   0.03439814814814815,\n",
       "   0.03469907407407408,\n",
       "   0.04780092592592593,\n",
       "   0.06357638888888889,\n",
       "   0.06960648148148148,\n",
       "   0.07405092592592592,\n",
       "   0.07916666666666666,\n",
       "   0.10730324074074074,\n",
       "   0.1399537037037037,\n",
       "   0.15505787037037036,\n",
       "   0.21010416666666668,\n",
       "   0.24189814814814814,\n",
       "   0.3577314814814815,\n",
       "   0.360787037037037,\n",
       "   0.4763425925925926,\n",
       "   0.47944444444444445,\n",
       "   0.4831828703703704,\n",
       "   0.4905439814814815,\n",
       "   0.4905787037037037,\n",
       "   0.5326273148148148,\n",
       "   0.5332523148148148,\n",
       "   0.5344097222222223,\n",
       "   0.5358449074074074,\n",
       "   0.5387037037037037,\n",
       "   0.5392361111111111,\n",
       "   0.542025462962963,\n",
       "   0.5566782407407408,\n",
       "   0.5589236111111111,\n",
       "   0.5594791666666666,\n",
       "   0.5598958333333334,\n",
       "   0.5614467592592592,\n",
       "   0.5680439814814815,\n",
       "   0.5688194444444444,\n",
       "   0.5737962962962962,\n",
       "   0.6322569444444445,\n",
       "   0.6353356481481481,\n",
       "   0.6408101851851852,\n",
       "   0.6451157407407407,\n",
       "   0.6519560185185185,\n",
       "   0.6632291666666666,\n",
       "   0.7922222222222223,\n",
       "   0.905787037037037,\n",
       "   0.9570717592592592,\n",
       "   0.9598842592592592,\n",
       "   0.9820717592592593,\n",
       "   1.0516203703703704,\n",
       "   1.9940625,\n",
       "   2.1063310185185187],\n",
       "  [0.0, 0.09349537037037037, 1.5378472222222221],\n",
       "  [0.0,\n",
       "   0.008055555555555555,\n",
       "   0.011666666666666667,\n",
       "   0.018912037037037036,\n",
       "   0.05380787037037037,\n",
       "   0.06641203703703703,\n",
       "   0.06831018518518518,\n",
       "   0.07061342592592593,\n",
       "   0.07851851851851852,\n",
       "   0.10209490740740741,\n",
       "   0.11195601851851852,\n",
       "   0.1467013888888889,\n",
       "   0.15108796296296295,\n",
       "   0.17127314814814815,\n",
       "   0.17173611111111112,\n",
       "   0.17207175925925927,\n",
       "   0.23625,\n",
       "   0.25,\n",
       "   0.31506944444444446,\n",
       "   0.37298611111111113,\n",
       "   0.510775462962963,\n",
       "   0.5426504629629629,\n",
       "   0.5509722222222222,\n",
       "   0.7496527777777777,\n",
       "   0.7653935185185186,\n",
       "   3.5878587962962962,\n",
       "   4.8875,\n",
       "   15.03761574074074,\n",
       "   61.99692129629629],\n",
       "  [0.0, 0.12893518518518518, 0.23189814814814816, 0.24606481481481482],\n",
       "  [0.0,\n",
       "   0.008368055555555556,\n",
       "   0.01193287037037037,\n",
       "   0.07388888888888889,\n",
       "   0.26109953703703703,\n",
       "   0.587037037037037],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   1.1574074074074073e-05,\n",
       "   1.1574074074074073e-05,\n",
       "   2.3148148148148147e-05,\n",
       "   0.002395833333333333,\n",
       "   0.05412037037037037,\n",
       "   0.057708333333333334,\n",
       "   0.08206018518518518,\n",
       "   0.08546296296296296,\n",
       "   0.0858912037037037,\n",
       "   0.35359953703703706,\n",
       "   0.48527777777777775,\n",
       "   0.5038541666666667,\n",
       "   0.6445601851851852,\n",
       "   0.6459722222222222,\n",
       "   2.2883449074074074],\n",
       "  [0.0,\n",
       "   0.01099537037037037,\n",
       "   0.22769675925925925,\n",
       "   0.2528125,\n",
       "   0.3630787037037037,\n",
       "   0.36420138888888887,\n",
       "   0.5364467592592592,\n",
       "   0.591099537037037,\n",
       "   0.5925462962962963,\n",
       "   0.8244328703703704,\n",
       "   0.9525694444444445,\n",
       "   2.431064814814815,\n",
       "   2.444328703703704,\n",
       "   3.246226851851852,\n",
       "   3.2472222222222222],\n",
       "  [0.0,\n",
       "   0.000925925925925926,\n",
       "   0.004097222222222223,\n",
       "   0.004097222222222223,\n",
       "   0.009699074074074074,\n",
       "   0.009710648148148149],\n",
       "  [0.0,\n",
       "   0.05178240740740741,\n",
       "   0.06288194444444445,\n",
       "   47.168645833333336,\n",
       "   47.435763888888886,\n",
       "   49.02096064814815,\n",
       "   52.60402777777778],\n",
       "  [0.0, 0.7056944444444444],\n",
       "  [0.0,\n",
       "   0.02863425925925926,\n",
       "   0.042199074074074076,\n",
       "   0.1655787037037037,\n",
       "   1.2891319444444445,\n",
       "   1.3773148148148149],\n",
       "  [0.0, 0.3735648148148148],\n",
       "  [0.0, 30.755034722222224],\n",
       "  [0.0, 0.24688657407407408],\n",
       "  [0.0,\n",
       "   0.0002199074074074074,\n",
       "   0.0052662037037037035,\n",
       "   0.1437037037037037,\n",
       "   0.16010416666666666,\n",
       "   0.20019675925925925,\n",
       "   0.21362268518518518,\n",
       "   0.2601967592592593,\n",
       "   0.2896412037037037,\n",
       "   0.33144675925925926,\n",
       "   0.3930439814814815,\n",
       "   0.4248958333333333,\n",
       "   0.4292592592592593,\n",
       "   0.4529166666666667,\n",
       "   0.4541203703703704,\n",
       "   0.45875,\n",
       "   0.4619097222222222,\n",
       "   0.46921296296296294,\n",
       "   0.6817361111111111,\n",
       "   0.6974074074074074,\n",
       "   0.6982523148148149,\n",
       "   0.9073726851851852,\n",
       "   0.9109027777777777,\n",
       "   0.9113310185185185,\n",
       "   0.9194675925925926,\n",
       "   0.9568287037037037,\n",
       "   0.9575115740740741,\n",
       "   0.9585185185185185,\n",
       "   1.0096643518518518,\n",
       "   1.401099537037037,\n",
       "   3.7693287037037035,\n",
       "   4.095289351851852,\n",
       "   5.510636574074074,\n",
       "   5.514421296296296,\n",
       "   5.528414351851852,\n",
       "   5.556875,\n",
       "   5.584722222222222,\n",
       "   5.615277777777778,\n",
       "   5.627476851851852,\n",
       "   5.642002314814815,\n",
       "   5.643368055555555,\n",
       "   5.646678240740741,\n",
       "   5.650925925925926,\n",
       "   5.653101851851852,\n",
       "   5.654525462962963,\n",
       "   5.659918981481481,\n",
       "   5.676099537037037,\n",
       "   5.847037037037037,\n",
       "   5.8696064814814815,\n",
       "   5.876400462962963,\n",
       "   5.8794560185185185,\n",
       "   5.968530092592593,\n",
       "   5.972986111111111,\n",
       "   5.983402777777778,\n",
       "   6.248252314814815,\n",
       "   6.250243055555556,\n",
       "   6.252962962962963,\n",
       "   6.368969907407408,\n",
       "   6.373055555555555,\n",
       "   6.376956018518518,\n",
       "   6.5511689814814815,\n",
       "   6.553819444444445,\n",
       "   6.555706018518518,\n",
       "   6.559097222222222,\n",
       "   6.560069444444444,\n",
       "   6.572418981481482,\n",
       "   6.574884259259259,\n",
       "   6.576006944444444,\n",
       "   6.585601851851852,\n",
       "   6.851354166666667,\n",
       "   6.861354166666667,\n",
       "   6.863958333333334,\n",
       "   6.866099537037037,\n",
       "   6.867835648148148,\n",
       "   6.868576388888889,\n",
       "   6.974826388888889,\n",
       "   7.081851851851852,\n",
       "   7.413356481481482,\n",
       "   16.522222222222222,\n",
       "   17.84835648148148,\n",
       "   34.73021990740741,\n",
       "   38.60697916666667,\n",
       "   42.62244212962963,\n",
       "   45.019050925925924,\n",
       "   47.47,\n",
       "   49.373206018518516,\n",
       "   49.37469907407407,\n",
       "   50.51050925925926,\n",
       "   51.279212962962966,\n",
       "   52.34934027777778,\n",
       "   52.35295138888889,\n",
       "   53.308761574074076],\n",
       "  [0.0,\n",
       "   0.00045138888888888887,\n",
       "   0.007858796296296296,\n",
       "   0.04400462962962963,\n",
       "   0.04407407407407407,\n",
       "   0.07799768518518518],\n",
       "  [0.0, 0.011006944444444444, 0.011585648148148149, 0.012314814814814815]],\n",
       " 'delta_times': [[1.0, 2.527210648148148],\n",
       "  [1.0, 0.0014467592592592592],\n",
       "  [1.0, 0.03166666666666667, 29.983414351851852, 407.29792824074076],\n",
       "  [1.0, 0.14180555555555555],\n",
       "  [1.0,\n",
       "   0.006423611111111111,\n",
       "   0.011238425925925928,\n",
       "   0.00980324074074074,\n",
       "   0.04994212962962963,\n",
       "   0.010821759259259253,\n",
       "   0.10214120370370372,\n",
       "   0.2353819444444444,\n",
       "   0.09901620370370368,\n",
       "   0.03894675925925928,\n",
       "   0.10503472222222221,\n",
       "   0.9909837962962964,\n",
       "   0.0013425925925925064,\n",
       "   0.13215277777777779],\n",
       "  [1.0,\n",
       "   0.09506944444444444,\n",
       "   0.27689814814814817,\n",
       "   0.0499074074074074,\n",
       "   0.4118287037037037,\n",
       "   0.3028240740740741,\n",
       "   2.023900462962963,\n",
       "   0.5193287037037035,\n",
       "   2.55369212962963],\n",
       "  [1.0, 0.22703703703703704, 1.763287037037037, 0.3067592592592592],\n",
       "  [1.0,\n",
       "   0.0030555555555555557,\n",
       "   0.34774305555555557,\n",
       "   0.2807060185185185,\n",
       "   2.1935416666666665],\n",
       "  [1.0,\n",
       "   0.0012731481481481483,\n",
       "   0.0030671296296296297,\n",
       "   0.0012731481481481483,\n",
       "   0.006712962962962962,\n",
       "   5.787037037037132e-05,\n",
       "   0.0019097222222222224,\n",
       "   0.00012731481481481448,\n",
       "   0.002280092592592594,\n",
       "   0.0020023148148148144,\n",
       "   0.0015740740740740715,\n",
       "   0.005659722222222222,\n",
       "   0.0008912037037037066,\n",
       "   0.0003124999999999968,\n",
       "   0.005104166666666667,\n",
       "   0.0027314814814814806,\n",
       "   0.005196759259259262,\n",
       "   0.008240740740740743,\n",
       "   0.3137152777777778,\n",
       "   0.0008101851851851638,\n",
       "   0.33039351851851856],\n",
       "  [1.0, 1.2914467592592593],\n",
       "  [1.0,\n",
       "   0.0014583333333333334,\n",
       "   0.11880787037037037,\n",
       "   0.06809027777777778,\n",
       "   0.016111111111111104],\n",
       "  [1.0,\n",
       "   0.07358796296296297,\n",
       "   0.005347222222222225,\n",
       "   0.021018518518518506,\n",
       "   0.02362268518518519,\n",
       "   0.012870370370370365,\n",
       "   0.027800925925925923,\n",
       "   0.01197916666666668,\n",
       "   0.037881944444444426,\n",
       "   0.005092592592592593,\n",
       "   0.03840277777777781,\n",
       "   0.17199074074074072,\n",
       "   0.005405092592592586,\n",
       "   0.011006944444444444,\n",
       "   0.004537037037037062,\n",
       "   0.03649305555555554,\n",
       "   0.3848032407407407,\n",
       "   1.1415162037037034,\n",
       "   0.8667824074074075],\n",
       "  [1.0,\n",
       "   0.0028587962962962963,\n",
       "   0.016377314814814813,\n",
       "   0.007372685185185187,\n",
       "   0.0013888888888888874,\n",
       "   0.00375,\n",
       "   0.0006018518518518534,\n",
       "   0.002048611111111112,\n",
       "   0.0003009259259259267,\n",
       "   0.01310185185185185,\n",
       "   0.015775462962962963,\n",
       "   0.006030092592592587,\n",
       "   0.004444444444444445,\n",
       "   0.00511574074074074,\n",
       "   0.028136574074074078,\n",
       "   0.03265046296296295,\n",
       "   0.015104166666666669,\n",
       "   0.055046296296296315,\n",
       "   0.031793981481481465,\n",
       "   0.11583333333333334,\n",
       "   0.0030555555555555336,\n",
       "   0.11555555555555558,\n",
       "   0.0031018518518518556,\n",
       "   0.0037384259259259367,\n",
       "   0.007361111111111096,\n",
       "   3.472222222222765e-05,\n",
       "   0.042048611111111134,\n",
       "   0.0006249999999999867,\n",
       "   0.0011574074074074403,\n",
       "   0.0014351851851851505,\n",
       "   0.002858796296296262,\n",
       "   0.0005324074074074536,\n",
       "   0.002789351851851807,\n",
       "   0.014652777777777848,\n",
       "   0.0022453703703703143,\n",
       "   0.0005555555555555314,\n",
       "   0.0004166666666667318,\n",
       "   0.0015509259259258723,\n",
       "   0.006597222222222254,\n",
       "   0.0007754629629629362,\n",
       "   0.004976851851851816,\n",
       "   0.05846064814814822,\n",
       "   0.003078703703703667,\n",
       "   0.005474537037037042,\n",
       "   0.0043055555555555625,\n",
       "   0.006840277777777737,\n",
       "   0.011273148148148171,\n",
       "   0.12899305555555562,\n",
       "   0.11356481481481473,\n",
       "   0.051284722222222245,\n",
       "   0.0028124999999999956,\n",
       "   0.022187500000000027,\n",
       "   0.0695486111111111,\n",
       "   0.9424421296296297,\n",
       "   0.1122685185185186],\n",
       "  [1.0, 0.09349537037037037, 1.4443518518518519],\n",
       "  [1.0,\n",
       "   0.008055555555555555,\n",
       "   0.003611111111111112,\n",
       "   0.007245370370370369,\n",
       "   0.034895833333333334,\n",
       "   0.012604166666666666,\n",
       "   0.0018981481481481488,\n",
       "   0.0023032407407407446,\n",
       "   0.007905092592592589,\n",
       "   0.023576388888888897,\n",
       "   0.009861111111111112,\n",
       "   0.03474537037037037,\n",
       "   0.004386574074074057,\n",
       "   0.020185185185185195,\n",
       "   0.00046296296296297057,\n",
       "   0.00033564814814815436,\n",
       "   0.06417824074074072,\n",
       "   0.013750000000000012,\n",
       "   0.06506944444444446,\n",
       "   0.05791666666666667,\n",
       "   0.13778935185185182,\n",
       "   0.03187499999999999,\n",
       "   0.008321759259259265,\n",
       "   0.19868055555555553,\n",
       "   0.015740740740740833,\n",
       "   2.822465277777778,\n",
       "   1.299641203703704,\n",
       "   10.150115740740741,\n",
       "   46.95930555555555],\n",
       "  [1.0, 0.12893518518518518, 0.10296296296296298, 0.01416666666666666],\n",
       "  [1.0,\n",
       "   0.008368055555555556,\n",
       "   0.003564814814814814,\n",
       "   0.06195601851851852,\n",
       "   0.18721064814814814,\n",
       "   0.3259375],\n",
       "  [1.0,\n",
       "   0.0,\n",
       "   1.1574074074074073e-05,\n",
       "   0.0,\n",
       "   1.1574074074074073e-05,\n",
       "   0.002372685185185185,\n",
       "   0.051724537037037034,\n",
       "   0.0035879629629629664,\n",
       "   0.024351851851851847,\n",
       "   0.0034027777777777823,\n",
       "   0.0004282407407407429,\n",
       "   0.2677083333333333,\n",
       "   0.1316782407407407,\n",
       "   0.01857638888888896,\n",
       "   0.1407060185185185,\n",
       "   0.0014120370370369617,\n",
       "   1.6423726851851852],\n",
       "  [1.0,\n",
       "   0.01099537037037037,\n",
       "   0.21670138888888887,\n",
       "   0.025115740740740744,\n",
       "   0.11026620370370371,\n",
       "   0.0011226851851851571,\n",
       "   0.17224537037037035,\n",
       "   0.05465277777777777,\n",
       "   0.0014467592592593004,\n",
       "   0.2318865740740741,\n",
       "   0.12813657407407408,\n",
       "   1.4784953703703705,\n",
       "   0.013263888888888964,\n",
       "   0.801898148148148,\n",
       "   0.000995370370370452],\n",
       "  [1.0,\n",
       "   0.000925925925925926,\n",
       "   0.0031712962962962966,\n",
       "   0.0,\n",
       "   0.005601851851851851,\n",
       "   1.1574074074075305e-05],\n",
       "  [1.0,\n",
       "   0.05178240740740741,\n",
       "   0.01109953703703704,\n",
       "   47.105763888888895,\n",
       "   0.26711805555554946,\n",
       "   1.5851967592592615,\n",
       "   3.583067129629633],\n",
       "  [1.0, 0.7056944444444444],\n",
       "  [1.0,\n",
       "   0.02863425925925926,\n",
       "   0.013564814814814818,\n",
       "   0.12337962962962962,\n",
       "   1.1235532407407407,\n",
       "   0.08818287037037043],\n",
       "  [1.0, 0.3735648148148148],\n",
       "  [1.0, 30.755034722222224],\n",
       "  [1.0, 0.24688657407407408],\n",
       "  [1.0,\n",
       "   0.0002199074074074074,\n",
       "   0.005046296296296296,\n",
       "   0.1384375,\n",
       "   0.016400462962962964,\n",
       "   0.040092592592592596,\n",
       "   0.013425925925925924,\n",
       "   0.0465740740740741,\n",
       "   0.02944444444444444,\n",
       "   0.04180555555555554,\n",
       "   0.06159722222222225,\n",
       "   0.0318518518518518,\n",
       "   0.004363425925925979,\n",
       "   0.023657407407407405,\n",
       "   0.0012037037037037068,\n",
       "   0.004629629629629595,\n",
       "   0.0031597222222222165,\n",
       "   0.007303240740740735,\n",
       "   0.21252314814814816,\n",
       "   0.015671296296296267,\n",
       "   0.0008449074074075025,\n",
       "   0.20912037037037035,\n",
       "   0.0035300925925925153,\n",
       "   0.0004282407407407707,\n",
       "   0.008136574074074088,\n",
       "   0.03736111111111107,\n",
       "   0.0006828703703704031,\n",
       "   0.0010069444444444908,\n",
       "   0.051145833333333224,\n",
       "   0.39143518518518516,\n",
       "   2.3682291666666666,\n",
       "   0.3259606481481483,\n",
       "   1.4153472222222225,\n",
       "   0.0037847222222220367,\n",
       "   0.013993055555555856,\n",
       "   0.028460648148147527,\n",
       "   0.027847222222222356,\n",
       "   0.03055555555555589,\n",
       "   0.012199074074073835,\n",
       "   0.014525462962962976,\n",
       "   0.0013657407407405842,\n",
       "   0.0033101851851853326,\n",
       "   0.004247685185185368,\n",
       "   0.002175925925925526,\n",
       "   0.0014236111111110006,\n",
       "   0.0053935185185185475,\n",
       "   0.016180555555555642,\n",
       "   0.17093749999999996,\n",
       "   0.022569444444444642,\n",
       "   0.006793981481481914,\n",
       "   0.003055555555555145,\n",
       "   0.08907407407407408,\n",
       "   0.004456018518518512,\n",
       "   0.010416666666666963,\n",
       "   0.26484953703703695,\n",
       "   0.001990740740740904,\n",
       "   0.0027199074074069074,\n",
       "   0.11600694444444493,\n",
       "   0.0040856481481474916,\n",
       "   0.0039004629629628695,\n",
       "   0.1742129629629634,\n",
       "   0.0026504629629631182,\n",
       "   0.0018865740740734438,\n",
       "   0.003391203703704271,\n",
       "   0.0009722222222219301,\n",
       "   0.01234953703703745,\n",
       "   0.002465277777777608,\n",
       "   0.0011226851851846575,\n",
       "   0.00959490740740776,\n",
       "   0.2657523148148151,\n",
       "   0.009999999999999787,\n",
       "   0.0026041666666669627,\n",
       "   0.0021412037037036313,\n",
       "   0.0017361111111107164,\n",
       "   0.0007407407407411526,\n",
       "   0.10625000000000018,\n",
       "   0.10702546296296234,\n",
       "   0.33150462962963,\n",
       "   9.10886574074074,\n",
       "   1.326134259259259,\n",
       "   16.88186342592593,\n",
       "   3.8767592592592592,\n",
       "   4.015462962962964,\n",
       "   2.3966087962962916,\n",
       "   2.4509490740740745,\n",
       "   1.9032060185185173,\n",
       "   0.001493055555556566,\n",
       "   1.1358101851851856,\n",
       "   0.7687037037037072,\n",
       "   1.0701273148148118,\n",
       "   0.0036111111111125638,\n",
       "   0.9558101851851859],\n",
       "  [1.0,\n",
       "   0.00045138888888888887,\n",
       "   0.007407407407407407,\n",
       "   0.036145833333333335,\n",
       "   6.944444444444142e-05,\n",
       "   0.03392361111111111],\n",
       "  [1.0, 0.011006944444444444, 0.0005787037037037045, 0.0007291666666666662]],\n",
       " 'marks': [[3060, 5080],\n",
       "  [4288, 3044],\n",
       "  [2541, 2541, 468, 4397],\n",
       "  [2541, 1985],\n",
       "  [2444,\n",
       "   4252,\n",
       "   1971,\n",
       "   5645,\n",
       "   4415,\n",
       "   6212,\n",
       "   387,\n",
       "   5742,\n",
       "   282,\n",
       "   457,\n",
       "   5645,\n",
       "   619,\n",
       "   619,\n",
       "   913],\n",
       "  [2541, 2541, 48, 4673, 1665, 4404, 993, 993, 4365],\n",
       "  [1255, 6420, 2290, 2901],\n",
       "  [2231, 6496, 4117, 1556, 4987],\n",
       "  [2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   1292,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   3074,\n",
       "   2541,\n",
       "   3074,\n",
       "   3074,\n",
       "   3074,\n",
       "   3074,\n",
       "   6696,\n",
       "   6696,\n",
       "   5785],\n",
       "  [1043, 5413],\n",
       "  [2541, 5617, 3646, 24, 5203],\n",
       "  [4862,\n",
       "   3951,\n",
       "   3577,\n",
       "   1607,\n",
       "   2118,\n",
       "   6233,\n",
       "   5445,\n",
       "   1144,\n",
       "   6448,\n",
       "   203,\n",
       "   6732,\n",
       "   1480,\n",
       "   5083,\n",
       "   1479,\n",
       "   1480,\n",
       "   5083,\n",
       "   6690,\n",
       "   2469,\n",
       "   4907],\n",
       "  [2541,\n",
       "   2541,\n",
       "   1086,\n",
       "   5206,\n",
       "   5206,\n",
       "   5206,\n",
       "   5206,\n",
       "   2143,\n",
       "   2143,\n",
       "   5310,\n",
       "   2767,\n",
       "   6401,\n",
       "   5781,\n",
       "   5781,\n",
       "   1165,\n",
       "   5176,\n",
       "   5206,\n",
       "   855,\n",
       "   1265,\n",
       "   5920,\n",
       "   5920,\n",
       "   5854,\n",
       "   1944,\n",
       "   111,\n",
       "   4361,\n",
       "   6472,\n",
       "   771,\n",
       "   771,\n",
       "   2204,\n",
       "   771,\n",
       "   771,\n",
       "   2204,\n",
       "   771,\n",
       "   5720,\n",
       "   5854,\n",
       "   771,\n",
       "   771,\n",
       "   771,\n",
       "   5854,\n",
       "   771,\n",
       "   771,\n",
       "   4378,\n",
       "   4378,\n",
       "   4378,\n",
       "   4378,\n",
       "   4378,\n",
       "   6671,\n",
       "   3396,\n",
       "   3683,\n",
       "   1404,\n",
       "   392,\n",
       "   2165,\n",
       "   392,\n",
       "   4560,\n",
       "   4003],\n",
       "  [2541, 2420, 4939],\n",
       "  [3748,\n",
       "   5702,\n",
       "   5752,\n",
       "   3441,\n",
       "   4531,\n",
       "   3441,\n",
       "   5752,\n",
       "   5752,\n",
       "   6697,\n",
       "   6777,\n",
       "   3441,\n",
       "   5752,\n",
       "   3441,\n",
       "   3809,\n",
       "   3809,\n",
       "   3809,\n",
       "   2451,\n",
       "   6151,\n",
       "   6626,\n",
       "   220,\n",
       "   5752,\n",
       "   5752,\n",
       "   6268,\n",
       "   5270,\n",
       "   5983,\n",
       "   1140,\n",
       "   3312,\n",
       "   6697,\n",
       "   2284],\n",
       "  [2437, 3224, 6188, 3134],\n",
       "  [3947, 3200, 6271, 2311, 3277, 588],\n",
       "  [2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   2541,\n",
       "   4670,\n",
       "   6779,\n",
       "   2541,\n",
       "   3581,\n",
       "   3581,\n",
       "   2659,\n",
       "   2541,\n",
       "   2684,\n",
       "   2541,\n",
       "   2541,\n",
       "   4604],\n",
       "  [3528,\n",
       "   1283,\n",
       "   6331,\n",
       "   639,\n",
       "   84,\n",
       "   84,\n",
       "   4330,\n",
       "   6028,\n",
       "   6028,\n",
       "   2756,\n",
       "   6268,\n",
       "   946,\n",
       "   946,\n",
       "   593,\n",
       "   593],\n",
       "  [2541, 4053, 2541, 2541, 2541, 2541],\n",
       "  [6426, 5860, 2400, 3294, 1031, 3343, 5066],\n",
       "  [2030, 6796],\n",
       "  [2541, 2219, 1273, 4969, 1475, 3878],\n",
       "  [6065, 3701],\n",
       "  [5691, 468],\n",
       "  [2541, 5082],\n",
       "  [3024,\n",
       "   3024,\n",
       "   3451,\n",
       "   3669,\n",
       "   5754,\n",
       "   1424,\n",
       "   5754,\n",
       "   1108,\n",
       "   6210,\n",
       "   465,\n",
       "   663,\n",
       "   758,\n",
       "   4038,\n",
       "   2801,\n",
       "   5458,\n",
       "   1905,\n",
       "   5684,\n",
       "   6813,\n",
       "   3669,\n",
       "   4723,\n",
       "   4723,\n",
       "   3244,\n",
       "   1089,\n",
       "   1089,\n",
       "   1089,\n",
       "   3669,\n",
       "   3669,\n",
       "   3669,\n",
       "   3669,\n",
       "   1089,\n",
       "   753,\n",
       "   5212,\n",
       "   1177,\n",
       "   4699,\n",
       "   5458,\n",
       "   1177,\n",
       "   5458,\n",
       "   1177,\n",
       "   5458,\n",
       "   1177,\n",
       "   5458,\n",
       "   5458,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   5458,\n",
       "   5458,\n",
       "   5684,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   5458,\n",
       "   5458,\n",
       "   5458,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   5458,\n",
       "   5458,\n",
       "   5458,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   5458,\n",
       "   5458,\n",
       "   5458,\n",
       "   5458,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   1177,\n",
       "   5458,\n",
       "   1177,\n",
       "   4699,\n",
       "   316,\n",
       "   2313,\n",
       "   3602,\n",
       "   4164,\n",
       "   2500,\n",
       "   6207,\n",
       "   5215,\n",
       "   615,\n",
       "   615,\n",
       "   5261,\n",
       "   101,\n",
       "   4175,\n",
       "   4175,\n",
       "   1182],\n",
       "  [4059, 5664, 5424, 4576, 4576, 4490],\n",
       "  [6402, 58, 1634, 2541]],\n",
       " 'tweet_type': [[1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1, 1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2],\n",
       "  [1, 1],\n",
       "  [1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [2, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3389cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('kdd_data/attempt_dev.pkl', 'rb') as f:\n",
    "    att = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17172b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arrival_times', 'delta_times', 'marks', 'tweet_type'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att['dev'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7004124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in split['arrival_times']:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "80123d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3252"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c6cbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
