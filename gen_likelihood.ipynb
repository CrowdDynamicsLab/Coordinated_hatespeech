{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4ca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from scipy.stats import beta\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import os\n",
    "import ast\n",
    "#from Content import *\n",
    "#from Venue import *\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590c2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "## People\n",
    "## Time\n",
    "## Topic\n",
    "## Media Contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a97211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './data/aliceysu'\n",
    "journalist = 'aliceysu'\n",
    "with open(os.path.join(out_dir, f'{journalist}_dict.pkl'), 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(out_dir, f'{journalist}_ids.pkl'), 'rb') as f:\n",
    "    map_id = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(out_dir, f'{journalist}_lan.pkl'), 'rb') as f:\n",
    "    map_lan = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(out_dir, f'{journalist}_type.pkl'), 'rb') as f:\n",
    "    map_type = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(out_dir, f'{journalist}_reply.pkl'), 'rb') as f:\n",
    "    map_reply = pickle.load(f)\n",
    "\n",
    "alice = pd.DataFrame.from_dict(data)\n",
    "alice_sort = alice.sort_values(by=['created_at'])\n",
    "conv = pd.read_csv(os.path.join(out_dir, f'{journalist}_conv_labels.csv'))\n",
    "\n",
    "data = pkl.load(open(os.path.join(out_dir, f'{journalist}_dict.pkl'), 'rb'))\n",
    "journal = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a6292f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "for item in conv['context']:\n",
    "    temp_s = ''\n",
    "    if item == '0':\n",
    "        contexts.append('Unified Twitter Taxonomy')\n",
    "\n",
    "    else:\n",
    "        for i in ast.literal_eval(item):\n",
    "            temp_s  += (i['domain']['name'] + ' ' + i['entity']['name'])\n",
    "        contexts.append(temp_s)\n",
    "    \n",
    "annotations = []\n",
    "for item in conv['annotations']:\n",
    "    temp_s = ''\n",
    "    if item == '0':\n",
    "        annotations.append('Others')\n",
    "\n",
    "    else:\n",
    "        for i in ast.literal_eval(item):\n",
    "            temp_s += i['type'] + ' ' + i['normalized_text']\n",
    "\n",
    "        annotations.append(temp_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ab438d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal['context'] = contexts\n",
    "journal['annotations'] = annotations\n",
    "journal_sort = journal.sort_values(by=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "8f424c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## topics\n",
    "## people\n",
    "ref_ids = []\n",
    "\n",
    "journal_sort['topics'] = None\n",
    "journal_sort['ppls'] = None\n",
    "conv_ids = set(journal_sort['conversation_id'])\n",
    "for conv in list(conv_ids):\n",
    "    test_d = journal_sort[journal_sort['conversation_id'] == conv]\n",
    "    for index, item in test_d.iterrows():\n",
    "        i = 0\n",
    "        tweet_id = item['tweet_id']\n",
    "        ref_id = item['reference_id']\n",
    "        conv_id = item['conversation_id']\n",
    "        topic1 = item['context']\n",
    "        anno1 = item['annotations']\n",
    "        if len(test_d) == 1:\n",
    "            topic2 = 'Unified Twitter Taxonomy'\n",
    "            anno2 = 'Others'\n",
    "            journal_sort.at[index, 'topics']=[text1, text2]\n",
    "            journal_sort.at[index, 'ppls']=[anno1, anno2]\n",
    "            continue\n",
    "        if ref_id not in ref_ids:\n",
    "            if tweet_id == test_d.iloc[0]['tweet_id']:\n",
    "                text2 = test_d[test_d['tweet_id']==test_d.iloc[1]['tweet_id']]['context'].item()\n",
    "                anno2 = test_d[test_d['tweet_id']==test_d.iloc[1]['tweet_id']]['annotations'].item()\n",
    "            else:\n",
    "                text2 = test_d.iloc[i-1]['context']\n",
    "                anno2 = test_d.iloc[i-1]['annotations']\n",
    "        else:\n",
    "            #print(tweet_id,ref_id)\n",
    "            text2 = test_d[test_d['tweet_id']==ref_id]['context'].item()\n",
    "            anno2 = test_d[test_d['tweet_id']==ref_id]['annotations'].item()\n",
    "\n",
    "        ref_ids.append(tweet_id)\n",
    "        \n",
    "        journal_sort.at[index, 'topics']=[text1, text2]\n",
    "        journal_sort.at[index, 'ppls']=[anno1, anno2]\n",
    "        #print(text2, journal_sort.at[index, 'topics'])\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "3f634ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_sort.to_csv(os.path.join(out_dir, f'{journalist}_context.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "692dbdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "10632it [17:00, 10.41it/s]\n"
     ]
    }
   ],
   "source": [
    "context_sims = []\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "for index, item in tqdm(journal_sort.iterrows()):\n",
    "    # Tokenize input text and convert to tensor\n",
    "    c1 = item['topics'][0]\n",
    "    c2 = item['topics'][1]\n",
    "    \n",
    "    a1 = item['ppls'][0]\n",
    "    a2 = item['ppls'][1]\n",
    "    inputs1 = tokenizer(c1, return_tensors=\"pt\")\n",
    "    inputs2 = tokenizer(c2, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(**inputs1)\n",
    "        outputs2 = model(**inputs2)\n",
    "\n",
    "    # The last hidden state is the sequence of hidden states of the last layer of the model\n",
    "    last_hidden_states1 = outputs1.last_hidden_state\n",
    "    last_hidden_states2 = outputs2.last_hidden_state\n",
    "\n",
    "    # Optionally, use the [CLS] token's embedding as the representation for the entire sentence\n",
    "    sentence_embedding1 = last_hidden_states1[:, 0, :]\n",
    "    sentence_embedding2 = last_hidden_states2[:, 0, :]\n",
    "\n",
    "    cosine = np.dot(sentence_embedding1,sentence_embedding2.T)/(norm(sentence_embedding1)*norm(sentence_embedding2))\n",
    "    context_sims.append(cosine)\n",
    "    #print(sentence_embedding.shape)\n",
    "    \n",
    "journal_sort['topics_sim'] = context_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "da53ee76",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "10632it [13:57, 12.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "anno_sims = []\n",
    "for index, item in tqdm(journal_sort.iterrows()):\n",
    "    # Tokenize input text and convert to tensor\n",
    "    c1 = item['topics'][0]\n",
    "    c2 = item['topics'][1]\n",
    "    \n",
    "    a1 = item['ppls'][0]\n",
    "    a2 = item['ppls'][1]\n",
    "    inputs1 = tokenizer(a1, return_tensors=\"pt\")\n",
    "    inputs2 = tokenizer(a2, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(**inputs1)\n",
    "        outputs2 = model(**inputs2)\n",
    "\n",
    "    # The last hidden state is the sequence of hidden states of the last layer of the model\n",
    "    last_hidden_states1 = outputs1.last_hidden_state\n",
    "    last_hidden_states2 = outputs2.last_hidden_state\n",
    "\n",
    "    # Optionally, use the [CLS] token's embedding as the representation for the entire sentence\n",
    "    sentence_embedding1 = last_hidden_states1[:, 0, :]\n",
    "    sentence_embedding2 = last_hidden_states2[:, 0, :]\n",
    "\n",
    "    cosine = np.dot(sentence_embedding1,sentence_embedding2.T)/(norm(sentence_embedding1)*norm(sentence_embedding2))\n",
    "    anno_sims.append(cosine)\n",
    "    #print(sentence_embedding.shape)\n",
    "    \n",
    "journal_sort['ppls_sim'] = anno_sims\n",
    "journal_sort = pd.read_csv(os.path.join(out_dir, f'{journalist}_context.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "6033f78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "034022e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_time = []\n",
    "test_d = journal_sort[journal_sort['conversation_id']==4]\n",
    "for index, item in test_d.iterrows():\n",
    "    anchor_time.append(datetime.strptime(item['created_at'][:19], date_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "c3c17c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = anchor_time[1] - anchor_time[0]\n",
    "anchor_hours = divmod(anchor.total_seconds() , 3600)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "b77bf36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(anchor_hours)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "941a8f68",
   "metadata": {},
   "source": [
    "date_format = \"%Y-%m-%dT%H:%M:%S\" \n",
    "datetime.strptime(data[0]['created_at'][:19], date_format)\n",
    "journal_sort.at[0, 'created_at'] - journal_sort.at[4, 'created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "7e097cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time\n",
    "ref_ids = []\n",
    "date_format = \"%Y-%m-%dT%H:%M:%S\" \n",
    "journal_sort['time gap'] = None\n",
    "conv_ids = set(journal_sort['conversation_id'])\n",
    "for conv in list(conv_ids):\n",
    "    test_d = journal_sort[journal_sort['conversation_id'] == conv]\n",
    "    time0 = datetime.strptime(test_d.iloc[0]['created_at'][:19], date_format)\n",
    "    k = 0\n",
    "    for index, item in test_d.iterrows():\n",
    "        tweet_id = item['tweet_id']\n",
    "        ref_id = item['reference_id']\n",
    "        conv_id = item['conversation_id']\n",
    "        time1 = datetime.strptime(item['created_at'][:19], date_format)\n",
    "        if len(test_d) == 1:\n",
    "            journal_sort.at[index, 'time gap']= float(anchor_hours) / 120\n",
    "            continue\n",
    "        if ref_id not in ref_ids:\n",
    "            if tweet_id == test_d.iloc[0]['tweet_id']:\n",
    "                time2 = datetime.strptime(item['created_at'][:19], date_format) - anchor\n",
    "            else:\n",
    "                time2 = datetime.strptime(test_d.iloc[k-1]['created_at'][:19], date_format)\n",
    "        else:\n",
    "            #print(test_d[test_d['tweet_id']==ref_id]['created_at'][:19].item())\n",
    "            time2 = datetime.strptime(test_d[test_d['tweet_id']==ref_id]['created_at'].item()[:19], date_format)\n",
    "    \n",
    "\n",
    "        ref_ids.append(tweet_id)\n",
    "        gap_in_s = (time1 - time2).total_seconds() \n",
    "        journal_sort.at[index, 'time gap']= float(divmod(gap_in_s, 3600)[0]) / 120\n",
    "        \n",
    "        k += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867368df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PA * Latest * Field * Self = 2*2*2*2 = 16\n",
    "## PA: Normal PA (p=0.1, p/#nodes + (1-p)indegree/sum_of_indegree), Uniform (1/#nodes)\n",
    "## Latest: Normal Latest (beta(10,1), x=1-(outyear-inyear)/(outyear-oldest_year)), Uniform (1/(outyear-oldest_year))\n",
    "## Field: Similar (1-(1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized), Different ((1-e^(-||x-y||_2))/(1-e^(-2)), x&y L2-normalized)\n",
    "## Self: Prefer (coauthors: 0.9/#coauthors, non-coauthors: 0.1/#non-coauthors), Not Prefer (coauthors: 0.1/#coauthors, non-coauthors: 0.9/#non-coauthors)\n",
    "\n",
    "## 1st: Normal_PA * Normal_Latest * Similar_Field * Prefer_Self\n",
    "## 2nd: Normal_PA * Normal_Latest * Similar_Field * NotPrefer_Self\n",
    "## 3rd: Normal_PA * Normal_Latest * Different_Field * Prefer_Self\n",
    "## 4th: Normal_PA * Normal_Latest * Different_Field * NotPrefer_Self\n",
    "## 5th: Normal_PA * Uniform_Latest * Similar_Field * Prefer_Self\n",
    "## 6th: Normal_PA * Uniform_Latest * Similar_Field * NotPrefer_Self\n",
    "## 7th: Normal_PA * Uniform_Latest * Different_Field * Prefer_Self\n",
    "## 8th: Normal_PA * Uniform_Latest * Different_Field * NotPrefer_Self\n",
    "## 9th: Uniform_PA * Normal_Latest * Similar_Field * Prefer_Self\n",
    "## 10th: Uniform_PA * Normal_Latest * Similar_Field * NotPrefer_Self\n",
    "## 11th: Uniform_PA * Normal_Latest * Different_Field * Prefer_Self\n",
    "## 12th: Uniform_PA * Normal_Latest * Different_Field * NotPrefer_Self\n",
    "## 13th: Uniform_PA * Uniform_Latest * Similar_Field * Prefer_Self\n",
    "## 14th: Uniform_PA * Uniform_Latest * Similar_Field * NotPrefer_Self\n",
    "## 15th: Uniform_PA * Uniform_Latest * Different_Field * Prefer_Self\n",
    "## 16th: Uniform_PA * Uniform_Latest * Different_Field * NotPrefer_Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "ea209ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "superbeta = beta(a=10,b=1)\n",
    "\n",
    "def cal_cite_edgeprobs(df):\n",
    "    edge_prob = []\n",
    "    for index, item in df.iterrows():\n",
    "         \n",
    "        ppl_sim = float(item['ppls_sim'][2:-2])\n",
    "        ppl_dif = 1 - ppl_sim\n",
    "\n",
    "        topic_sim = float(item['topics_sim'][2:-2])\n",
    "        topic_dif = 1 - topic_sim\n",
    "\n",
    "        pnormal_latest = superbeta.pdf(1-item['time gap']) + 1e-20\n",
    "        puniform_latest = 1 / 168\n",
    "\n",
    "        temp1 = np.array([ppl_sim, ppl_dif])\n",
    "        temp2 = np.outer([topic_sim,topic_dif],[pnormal_latest,puniform_latest]).flatten()\n",
    "        result = np.outer(temp1,temp2).flatten()\n",
    "        edge_prob.append(result)\n",
    "    \n",
    "    return np.array(edge_prob, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "85dbdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeprob = cal_cite_edgeprobs(journal_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "0667dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_dir, f'{journalist}_edgeprob.pkl'),'wb') as f:\n",
    "    pickle.dump(edgeprob, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aeb40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
